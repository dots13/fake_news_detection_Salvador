{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dots13/fake_news_detection_Salvador/blob/master/TF-IDF/Tf_IDF_boosting_models_OPTUNA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHjxYmxRxWLc",
        "outputId": "8cecbdc1-142f-4a7d-cbe2-1d2cfae42327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.0-py3-none-any.whl (379 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.29)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.2 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.0\n"
          ]
        }
      ],
      "source": [
        "#!pip3 install catboost\n",
        "!pip3 install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Ith0YzN5P7vh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "pd.set_option('max_colwidth', 400)\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "#from catboost import CatBoostClassifier\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GrPKZIiP-Ck",
        "outputId": "4c3ce29a-0cd2-46b6-a7ae-85d7e99fc631"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdrive')\n",
        "path = '/content/gdrive/My Drive/files/fake-news'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls gdrive/MyDrive/files/fake-news/preprocessed-data-for-modelling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHrTZ90Zhf2z",
        "outputId": "da0e9ec3-9014-46fe-fb65-460008cea62b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.json  train.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def eval_report(y_test, y_pred):\n",
        "    print(f'Accuracy score:{metrics.accuracy_score(y_test, y_pred):.4f}')\n",
        "    print(f'Balanced accuracy score:{metrics.balanced_accuracy_score(y_test, y_pred):.4f}')\n",
        "    print(f'F-1 score:{metrics.f1_score(y_test, y_pred):.4f}')\n",
        "    print(f'ROC-AUC score:{metrics.roc_auc_score(y_test, y_pred):.4f}')"
      ],
      "metadata": {
        "id": "GedP7epXycI0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Function for confusion matrix visualization\n",
        "def confusion_matrix_visualization(cf_matrix):\n",
        "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
        "    group_counts = [f'{value:.0f}' for value in cf_matrix.flatten()]\n",
        "    group_percentages = [f'{value:.2%}' for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
        "              zip(group_names,group_counts,group_percentages)]\n",
        "    labels = np.asarray(labels).reshape(2,2)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(7,5))\n",
        "    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "fFr-WO6MyZ_u"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "s5rdfAbdRt7g"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(path + '/train_test_anastasiia/train_clean.csv')\n",
        "df_test = pd.read_csv(path + '/train_test_anastasiia/test_clean.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaner = SpanishTextCleaner()\n",
        "#df_train['cleaned_text'] = df_train['text'].apply(lambda x: cleaner.clean_and_replace(x))\n",
        "#df_test['cleaned_text'] = df_test['text'].apply(lambda x: cleaner.clean_and_replace(x))"
      ],
      "metadata": {
        "id": "0dyjcVrEDKzA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qY9V61tTX_Gv"
      },
      "outputs": [],
      "source": [
        "stopwords = ['de',\n",
        "             'la',\n",
        "\t           'que',\n",
        "\t           'el',\n",
        "\t           'en',\n",
        "\t           'y',\n",
        "\t           'a',\n",
        "\t           'los',\n",
        "\t           'del',\n",
        "\t           'se',\n",
        "\t           'las',\n",
        "\t           'por',\n",
        "\t           'un',\n",
        "\t           'para',\n",
        "\t           'con',\n",
        "\t           'no',\n",
        "\t           'una',\n",
        "\t           'su',\n",
        "\t           'al',\n",
        "\t           'lo',\n",
        "\t           'como',\n",
        "\t           'más',\n",
        "\t           'pero',\n",
        "\t           'sus',\n",
        "\t           'le',\n",
        "\t           'ya',\n",
        "\t           'o',\n",
        "\t           'este',\n",
        "\t           'sí',\n",
        "\t           'porque',\n",
        "\t           'esta',\n",
        "\t           'entre',\n",
        "\t           'cuando',\n",
        "\t           'muy',\n",
        "\t           'sin',\n",
        "\t           'sobre',\n",
        "\t           'también',\n",
        "\t           'me',\n",
        "\t           'hasta',\n",
        "\t           'hay',\n",
        "\t           'donde',\n",
        "\t           'quien',\n",
        "\t           'desde',\n",
        "\t           'todo',\n",
        "\t           'nos',\n",
        "\t           'durante',\n",
        "\t           'todos',\n",
        "\t           'uno',\n",
        "\t           'les',\n",
        "\t           'ni',\n",
        "\t           'contra',\n",
        "\t           'otros',\n",
        "\t           'ese',\n",
        "\t           'eso',\n",
        "\t           'ante',\n",
        "\t           'ellos',\n",
        "\t           'e',\n",
        "\t           'esto',\n",
        "\t           'mí',\n",
        "\t           'antes',\n",
        "\t           'algunos',\n",
        "\t           'qué',\n",
        "\t           'unos',\n",
        "\t           'yo',\n",
        "\t           'otro',\n",
        "\t           'otras',\n",
        "\t           'otra',\n",
        "\t           'él',\n",
        "\t           'tanto',\n",
        "\t           'esa',\n",
        "\t           'estos',\n",
        "\t           'mucho',\n",
        "\t           'quienes',\n",
        "\t           'nada',\n",
        "\t           'muchos',\n",
        "\t           'cual',\n",
        "\t           'poco',\n",
        "\t           'ella',\n",
        "\t           'estar',\n",
        "\t           'estas',\n",
        "\t           'algunas',\n",
        "\t           'algo',\n",
        "\t           'nosotros',\n",
        "\t           'mi',\n",
        "\t           'mis',\n",
        "\t           'tú',\n",
        "\t           'te',\n",
        "\t           'ti',\n",
        "\t           'tu',\n",
        "\t           'tus',\n",
        "\t           'ellas',\n",
        "\t           'nosotras',\n",
        "\t           'vosotros',\n",
        "\t           'vosotras',\n",
        "\t           'os',\n",
        "\t           'mío',\n",
        "\t           'mía',\n",
        "\t           'míos',\n",
        "\t           'mías',\n",
        "\t           'tuyo',\n",
        "\t           'tuya',\n",
        "\t           'tuyos',\n",
        "\t           'tuyas',\n",
        "\t           'suyo',\n",
        "\t           'suya',\n",
        "\t           'suyos',\n",
        "\t           'suyas',\n",
        "\t           'nuestro',\n",
        "\t           'nuestra',\n",
        "\t           'nuestros',\n",
        "\t           'nuestras',\n",
        "\t           'vuestro',\n",
        "\t           'vuestra',\n",
        "\t           'vuestros',\n",
        "\t           'vuestras',\n",
        "\t           'esos',\n",
        "\t           'esas',\n",
        "\t           'estoy',\n",
        "\t           'estás',\n",
        "\t           'está',\n",
        "\t           'estamos',\n",
        "\t           'estáis',\n",
        "\t           'están',\n",
        "\t           'esté',\n",
        "\t           'estés',\n",
        "\t           'estemos',\n",
        "\t           'estéis',\n",
        "\t           'estén',\n",
        "\t           'estaré',\n",
        "\t           'estarás',\n",
        "\t           'estará',\n",
        "\t           'estaremos',\n",
        "\t           'estaréis',\n",
        "\t           'estarán',\n",
        "\t           'estaría',\n",
        "\t           'estarías',\n",
        "\t           'estaríamos',\n",
        "\t           'estaríais',\n",
        "\t           'estarían',\n",
        "\t           'estaba',\n",
        "\t           'estabas',\n",
        "\t           'estábamos',\n",
        "\t           'estabais',\n",
        "\t           'estaban',\n",
        "\t           'estuve',\n",
        "\t           'estuviste',\n",
        "\t           'estuvo',\n",
        "\t           'estuvimos',\n",
        "\t           'estuvisteis',\n",
        "\t           'estuvieron',\n",
        "\t           'estuviera',\n",
        "\t           'estuvieras',\n",
        "\t           'estuviéramos',\n",
        "\t           'estuvierais',\n",
        "\t           'estuvieran',\n",
        "\t           'estuviese',\n",
        "\t           'estuvieses',\n",
        "\t           'estuviésemos',\n",
        "\t           'estuvieseis',\n",
        "\t           'estuviesen',\n",
        "\t           'estando',\n",
        "\t           'estado',\n",
        "\t           'estada',\n",
        "\t           'estados',\n",
        "\t           'estadas',\n",
        "\t           'estad',\n",
        "\t           'he',\n",
        "\t           'has',\n",
        "\t           'ha',\n",
        "\t           'hemos',\n",
        "\t           'habéis',\n",
        "\t           'han',\n",
        "\t           'haya',\n",
        "\t           'hayas',\n",
        "\t           'hayamos',\n",
        "\t           'hayáis',\n",
        "\t           'hayan',\n",
        "\t           'habré',\n",
        "\t           'habrás',\n",
        "\t           'habrá',\n",
        "\t           'habremos',\n",
        "\t           'habréis',\n",
        "\t           'habrán',\n",
        "\t           'habría',\n",
        "\t           'habrías',\n",
        "\t           'habríamos',\n",
        "\t           'habríais',\n",
        "\t           'habrían',\n",
        "\t           'había',\n",
        "\t           'habías',\n",
        "\t           'habíamos',\n",
        "\t           'habíais',\n",
        "\t           'habían',\n",
        "\t           'hube',\n",
        "\t           'hubiste',\n",
        "\t           'hubo',\n",
        "\t           'hubimos',\n",
        "\t           'hubisteis',\n",
        "\t           'hubieron',\n",
        "\t           'hubiera',\n",
        "\t           'hubieras',\n",
        "\t           'hubiéramos',\n",
        "\t           'hubierais',\n",
        "\t           'hubieran',\n",
        "\t           'hubiese',\n",
        "\t           'hubieses',\n",
        "\t           'hubiésemos',\n",
        "\t           'hubieseis',\n",
        "\t           'hubiesen',\n",
        "\t           'habiendo',\n",
        "\t           'habido',\n",
        "\t           'habida',\n",
        "\t           'habidos',\n",
        "\t           'habidas',\n",
        "\t           'soy',\n",
        "\t           'eres',\n",
        "\t           'es',\n",
        "\t           'somos',\n",
        "\t           'sois',\n",
        "\t           'son',\n",
        "\t           'sea',\n",
        "\t           'seas',\n",
        "\t           'seamos',\n",
        "\t           'seáis',\n",
        "\t           'sean',\n",
        "\t           'seré',\n",
        "\t           'serás',\n",
        "\t           'será',\n",
        "\t           'seremos',\n",
        "\t           'seréis',\n",
        "\t           'serán',\n",
        "\t           'sería',\n",
        "\t           'serías',\n",
        "\t           'seríamos',\n",
        "\t           'seríais',\n",
        "\t           'serían',\n",
        "\t           'era',\n",
        "\t           'eras',\n",
        "\t           'éramos',\n",
        "\t           'erais',\n",
        "\t           'eran',\n",
        "\t           'fui',\n",
        "\t           'fuiste',\n",
        "\t           'fue',\n",
        "\t           'fuimos',\n",
        "\t           'fuisteis',\n",
        "\t           'fueron',\n",
        "\t           'fuera',\n",
        "\t           'fueras',\n",
        "\t           'fuéramos',\n",
        "\t           'fuerais',\n",
        "\t           'fueran',\n",
        "\t           'fuese',\n",
        "\t           'fueses',\n",
        "\t           'fuésemos',\n",
        "\t           'fueseis',\n",
        "\t           'fuesen',\n",
        "\t           'sintiendo',\n",
        "\t           'sentido',\n",
        "\t           'sentida',\n",
        "\t           'sentidos',\n",
        "\t           'sentidas',\n",
        "\t           'siente',\n",
        "\t           'sentid',\n",
        "\t           'tengo',\n",
        "\t           'tienes',\n",
        "\t           'tiene',\n",
        "\t           'tenemos',\n",
        "\t           'tenéis',\n",
        "\t           'tienen',\n",
        "\t           'tenga',\n",
        "\t           'tengas',\n",
        "\t           'tengamos',\n",
        "\t           'tengáis',\n",
        "\t           'tengan',\n",
        "\t           'tendré',\n",
        "\t           'tendrás',\n",
        "\t           'tendrá',\n",
        "\t           'tendremos',\n",
        "\t           'tendréis',\n",
        "\t           'tendrán',\n",
        "\t           'tendría',\n",
        "\t           'tendrías',\n",
        "\t           'tendríamos',\n",
        "\t           'tendríais',\n",
        "\t           'tendrían',\n",
        "\t           'tenía',\n",
        "\t           'tenías',\n",
        "\t           'teníamos',\n",
        "\t           'teníais',\n",
        "\t           'tenían',\n",
        "\t           'tuve',\n",
        "\t           'tuviste',\n",
        "\t           'tuvo',\n",
        "\t           'tuvimos',\n",
        "\t           'tuvisteis',\n",
        "\t           'tuvieron',\n",
        "\t           'tuviera',\n",
        "\t           'tuvieras',\n",
        "\t           'tuviéramos',\n",
        "\t           'tuvierais',\n",
        "\t           'tuvieran',\n",
        "\t           'tuviese',\n",
        "\t           'tuvieses',\n",
        "\t           'tuviésemos',\n",
        "\t           'tuvieseis',\n",
        "\t           'tuviesen',\n",
        "\t           'teniendo',\n",
        "\t           'tenido',\n",
        "\t           'tenida',\n",
        "\t           'tenidos',\n",
        "\t           'tenidas',\n",
        "\t           'tened'\n",
        "             ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5xtIkYlEZjEQ"
      },
      "outputs": [],
      "source": [
        "y_train = df_train.fake_news_class\n",
        "y_test = df_test.fake_news_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9ZQw2STaVAD",
        "outputId": "8754e3c0-0769-4663-c759-1383e59d1e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    0.578243\n",
            "0    0.421757\n",
            "Name: fake_news_class, dtype: float64\n",
            "1    0.576538\n",
            "0    0.423462\n",
            "Name: fake_news_class, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(y_train.value_counts()/len(y_train))\n",
        "print(y_test.value_counts()/len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2mIeFsx9aoqC"
      },
      "outputs": [],
      "source": [
        "mapping = {0: 1, 1: 0}\n",
        "\n",
        "# Invert the values using map\n",
        "y_train = y_train.map(mapping)\n",
        "y_test = y_test.map(mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK2_HiXVa0eF",
        "outputId": "1ec75249-6b62-4b1a-acac-9db67738669d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    0.578243\n",
            "1    0.421757\n",
            "Name: fake_news_class, dtype: float64\n",
            "0    0.576538\n",
            "1    0.423462\n",
            "Name: fake_news_class, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(y_train.value_counts()/len(y_train))\n",
        "print(y_test.value_counts()/len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TfidfVectorizer hyperparameters tuning\n",
        "def objective(trial):\n",
        "    # Define hyperparameters to be tuned\n",
        "    max_features = trial.suggest_int('max_features', 3000, 4500)\n",
        "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
        "    X_tfidf = vectorizer.fit_transform(df_train.cleaned_text)\n",
        "    X_train_optuna, X_val, y_train_optuna, y_val = train_test_split(X_tfidf, y_train, test_size=0.2, random_state=10)\n",
        "    clf = MultinomialNB()\n",
        "    clf.fit(X_train_optuna, y_train_optuna)\n",
        "    #y_pred = clf.predict(X_val)\n",
        "    #accuracy = metrics.roc_auc_score(y_val, y_pred)\n",
        "\n",
        "    scores = cross_val_score(clf, X_train_optuna, y_train_optuna, cv=5, scoring='roc_auc')\n",
        "    #roc_auc = roc_auc_score(y_test, predictions_xgb)\n",
        "    return np.mean(scores)"
      ],
      "metadata": {
        "id": "UEUdNX0E8x2Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=20)\n",
        "print('Best trial:')\n",
        "trial = study.best_trial\n",
        "print('  Value: {}'.format(trial.value))\n",
        "print('  Params: ')\n",
        "for key, value in trial.params.items():\n",
        "  print('    {}: {}'.format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEm2k5tL9l3F",
        "outputId": "cb3a9670-96f3-4cab-dc09-17ae5f22efd7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-30 23:52:42,846] A new study created in memory with name: no-name-4e321be9-4d84-4c26-8ebd-05ad6a8b6341\n",
            "[I 2024-03-30 23:52:44,160] Trial 0 finished with value: 0.7984653754102642 and parameters: {'max_features': 3974}. Best is trial 0 with value: 0.7984653754102642.\n",
            "[I 2024-03-30 23:52:45,403] Trial 1 finished with value: 0.7991837834537516 and parameters: {'max_features': 3575}. Best is trial 1 with value: 0.7991837834537516.\n",
            "[I 2024-03-30 23:52:47,107] Trial 2 finished with value: 0.7994767300753132 and parameters: {'max_features': 3246}. Best is trial 2 with value: 0.7994767300753132.\n",
            "[I 2024-03-30 23:52:48,384] Trial 3 finished with value: 0.7993319269680006 and parameters: {'max_features': 3207}. Best is trial 2 with value: 0.7994767300753132.\n",
            "[I 2024-03-30 23:52:49,673] Trial 4 finished with value: 0.7991287091955352 and parameters: {'max_features': 3629}. Best is trial 2 with value: 0.7994767300753132.\n",
            "[I 2024-03-30 23:52:50,947] Trial 5 finished with value: 0.7984304151438948 and parameters: {'max_features': 4211}. Best is trial 2 with value: 0.7994767300753132.\n",
            "[I 2024-03-30 23:52:52,236] Trial 6 finished with value: 0.7996629167935987 and parameters: {'max_features': 3516}. Best is trial 6 with value: 0.7996629167935987.\n",
            "[I 2024-03-30 23:52:54,154] Trial 7 finished with value: 0.7994544769875 and parameters: {'max_features': 3455}. Best is trial 6 with value: 0.7996629167935987.\n",
            "[I 2024-03-30 23:52:56,350] Trial 8 finished with value: 0.7993111006595891 and parameters: {'max_features': 3209}. Best is trial 6 with value: 0.7996629167935987.\n",
            "[I 2024-03-30 23:52:57,623] Trial 9 finished with value: 0.7995373530002879 and parameters: {'max_features': 3344}. Best is trial 6 with value: 0.7996629167935987.\n",
            "[I 2024-03-30 23:52:58,892] Trial 10 finished with value: 0.7986941728174768 and parameters: {'max_features': 4497}. Best is trial 6 with value: 0.7996629167935987.\n",
            "[I 2024-03-30 23:53:00,164] Trial 11 finished with value: 0.7987007887702868 and parameters: {'max_features': 3861}. Best is trial 6 with value: 0.7996629167935987.\n",
            "[I 2024-03-30 23:53:01,452] Trial 12 finished with value: 0.7996833647943701 and parameters: {'max_features': 3389}. Best is trial 12 with value: 0.7996833647943701.\n",
            "[I 2024-03-30 23:53:02,717] Trial 13 finished with value: 0.7988462266882468 and parameters: {'max_features': 3751}. Best is trial 12 with value: 0.7996833647943701.\n",
            "[I 2024-03-30 23:53:03,986] Trial 14 finished with value: 0.799302499075164 and parameters: {'max_features': 3015}. Best is trial 12 with value: 0.7996833647943701.\n",
            "[I 2024-03-30 23:53:05,230] Trial 15 finished with value: 0.7996912520374726 and parameters: {'max_features': 3514}. Best is trial 15 with value: 0.7996912520374726.\n",
            "[I 2024-03-30 23:53:06,811] Trial 16 finished with value: 0.798899638806158 and parameters: {'max_features': 4041}. Best is trial 15 with value: 0.7996912520374726.\n",
            "[I 2024-03-30 23:53:09,086] Trial 17 finished with value: 0.7993053411413067 and parameters: {'max_features': 3014}. Best is trial 15 with value: 0.7996912520374726.\n",
            "[I 2024-03-30 23:53:10,621] Trial 18 finished with value: 0.7995324946105387 and parameters: {'max_features': 3412}. Best is trial 15 with value: 0.7996912520374726.\n",
            "[I 2024-03-30 23:53:12,008] Trial 19 finished with value: 0.7988812315842039 and parameters: {'max_features': 3698}. Best is trial 15 with value: 0.7996912520374726.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial:\n",
            "  Value: 0.7996912520374726\n",
            "  Params: \n",
            "    max_features: 3514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WvP7A8_sXzyj"
      },
      "outputs": [],
      "source": [
        "# Initialize the TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=3500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "T2gYOqNmX0Or"
      },
      "outputs": [],
      "source": [
        "# Fit and transform the training set, transform the testing set\n",
        "X_train_tfidf = vectorizer.fit_transform(df_train.cleaned_text)\n",
        "X_test_tfidf = vectorizer.transform(df_test.cleaned_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGl0F3PfYonX",
        "outputId": "134e2b5a-f2b4-4fa3-aae0-5e4a6f9418a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<49097x3500 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 1035521 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "X_train_tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "n3UVqzkKZKU0"
      },
      "outputs": [],
      "source": [
        "#Baseline model\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "predicted = clf.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, predicted)\n",
        "confusion_matrix_visualization(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "PwACWiE-KUK8",
        "outputId": "676d1fdb-7922-446d-9ed7-5eb2b27c8d0b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_report(y_test, predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1rrMnFjy1Bx",
        "outputId": "41f6d410-5458-4498-9848-97e1b23f756a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score:0.7580\n",
            "Balanced accuracy score:0.7226\n",
            "F-1 score:0.6323\n",
            "ROC-AUC score:0.7226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OW7kAOKGgi2K"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/gdrive/My Drive/embedding/tf_idf_3500.pkl', 'wb') as f:\n",
        "    pickle.dump(vectorizer, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izBYpq_gx-63"
      },
      "source": [
        "**Catboost**  \n",
        "\n",
        "Very resource-intensive, requires GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "jcgZ5jdYh-X7",
        "outputId": "3dbe225c-ff3e-4834-8229-747b8c9a1c0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.054327\n",
            "0:\tlearn: 0.6754015\ttotal: 866ms\tremaining: 14m 25s\n",
            "1:\tlearn: 0.6598201\ttotal: 1.94s\tremaining: 16m 7s\n",
            "2:\tlearn: 0.6478855\ttotal: 2.95s\tremaining: 16m 21s\n",
            "3:\tlearn: 0.6362503\ttotal: 3.75s\tremaining: 15m 35s\n",
            "4:\tlearn: 0.6261068\ttotal: 4.48s\tremaining: 14m 51s\n",
            "5:\tlearn: 0.6171357\ttotal: 5.03s\tremaining: 13m 53s\n",
            "6:\tlearn: 0.6101763\ttotal: 5.57s\tremaining: 13m 9s\n",
            "7:\tlearn: 0.6033938\ttotal: 6.12s\tremaining: 12m 38s\n",
            "8:\tlearn: 0.5968936\ttotal: 6.67s\tremaining: 12m 14s\n",
            "9:\tlearn: 0.5918005\ttotal: 7.21s\tremaining: 11m 54s\n",
            "10:\tlearn: 0.5864139\ttotal: 7.78s\tremaining: 11m 39s\n",
            "11:\tlearn: 0.5828653\ttotal: 8.31s\tremaining: 11m 24s\n",
            "12:\tlearn: 0.5777300\ttotal: 8.87s\tremaining: 11m 13s\n",
            "13:\tlearn: 0.5743156\ttotal: 9.42s\tremaining: 11m 3s\n",
            "14:\tlearn: 0.5712129\ttotal: 9.98s\tremaining: 10m 55s\n",
            "15:\tlearn: 0.5678269\ttotal: 10.7s\tremaining: 10m 55s\n",
            "16:\tlearn: 0.5655937\ttotal: 11.6s\tremaining: 11m 11s\n",
            "17:\tlearn: 0.5630142\ttotal: 12.6s\tremaining: 11m 25s\n",
            "18:\tlearn: 0.5610190\ttotal: 13.5s\tremaining: 11m 36s\n",
            "19:\tlearn: 0.5582562\ttotal: 14.1s\tremaining: 11m 31s\n",
            "20:\tlearn: 0.5558481\ttotal: 14.6s\tremaining: 11m 22s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-6de90cacd283>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictions_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F1: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5199\u001b[0m             \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5201\u001b[0;31m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[1;32m   5202\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5203\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2395\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Training plots'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2396\u001b[0;31m                 self._train(\n\u001b[0m\u001b[1;32m   2397\u001b[0m                     \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m                     \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1776\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1777\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model_cat = CatBoostClassifier()\n",
        "model_cat.fit(X_train_tfidf, y_train)\n",
        "predictions_cat = model_cat.predict(X_test_tfidf)\n",
        "print(metrics.classification_report(y_test, predictions_cat))\n",
        "print('F1: ', metrics.f1_score(y_test, predictions_cat))\n",
        "print('ROC_AUC: ', metrics.roc_auc_score(y_test, predictions_cat))\n",
        "print(metrics.confusion_matrix(y_test, predictions_cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lqi_QcsSS1Hz"
      },
      "outputs": [],
      "source": [
        "model_cat.save_model('/content/gdrive/My Drive/models_fake_news/catboost_model.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGmYNuVJbgw_"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 700, 1200),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "        'depth': trial.suggest_int('max_depth', 4, 8),\n",
        "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 2, 5),\n",
        "       # 'bagging_temperature': trial.suggest_float(\"bagging_temperature\", 0, 20),\n",
        "        'auto_class_weights': trial.suggest_categorical('auto_class_weights', [None,'Balanced']),\n",
        "        #'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 10),\n",
        "        #'subsample': trial.suggest_float('subsample', 0.01, 0.1),\n",
        "       #'task_type': 'GPU',\n",
        "       'boosting_type': 'Ordered'\n",
        "      # 'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
        "    }\n",
        "    model = CatBoostClassifier(**params, silent=True)\n",
        "\n",
        "    #model.fit(X_train_tfidf, y_train)\n",
        "    #predictions = model.predict(X_test_tfidf)\n",
        "    #f1 = metrics.f1_score(y_test, predictions)\n",
        "    scores = cross_val_score(model, X_train_tfidf, y_train, cv=5, scoring='f1')\n",
        "    #roc_auc = roc_auc_score(y_test, predictions_xgb)\n",
        "    return np.mean(scores)\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JbObiExe-xo",
        "outputId": "e5003a01-7a51-45f9-db20-751354dc9d39"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-28 01:24:50,445] A new study created in memory with name: no-name-f7e2b11e-365d-4279-9564-12eeb81461c6\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters and best F1 score\n",
        "best_params = study.best_params\n",
        "best_score = study.best_value"
      ],
      "metadata": {
        "id": "Tp9ektPfUJjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = CatBoostClassifier(**best_params)\n",
        "best_model.fit(X_train_tfidf, y_train)\n",
        "predictions_cat = best_model.predict(X_test_tfidf)\n",
        "print(metrics.classification_report(y_test, predictions_cat))\n",
        "print('F1: ', metrics.f1_score(y_test, predictions_cat))\n",
        "print('ROC_AUC: ', metrics.roc_auc_score(y_test, predictions_cat))\n",
        "print(metrics.confusion_matrix(y_test, predictions_cat))"
      ],
      "metadata": {
        "id": "aUabBt_lUWY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cat.save_model('/content/gdrive/My Drive/models_fake_news/catboost_model_best.bin')"
      ],
      "metadata": {
        "id": "DN1PVQnQUnIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43SldmAtbttU"
      },
      "source": [
        "**XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_samples = np.sum(y_train == 1)\n",
        "negative_samples = np.sum(y_train == 0)\n",
        "imbalance_ratio = negative_samples / positive_samples"
      ],
      "metadata": {
        "id": "r_usebcjBsVR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_xgb = xgb.XGBClassifier(scale_pos_weight=imbalance_ratio)\n",
        "model_xgb.fit(X_train_tfidf, y_train)\n",
        "predictions_xgb = model_xgb.predict(X_test_tfidf)\n",
        "eval_report(y_test, predictions_xgb)\n",
        "cm = confusion_matrix(y_test, predictions_xgb)\n",
        "confusion_matrix_visualization(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "vLYi4wpiB5jJ",
        "outputId": "8a0c96e7-210f-4a58-c95a-56961755ebaf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score:0.7895\n",
            "Balanced accuracy score:0.7650\n",
            "F-1 score:0.7087\n",
            "ROC-AUC score:0.7650\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "genVSKuAjX0X"
      },
      "outputs": [],
      "source": [
        "model_xgb.save_model('/content/gdrive/My Drive/models_fake_news/xgboost_model.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMOGZPgvfzFU"
      },
      "source": [
        "**XGBoost + OPTUNA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PZMJD9dYkrUZ"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 4, 9),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.1, 1.0),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 170),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 15),\n",
        "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
        "        'subsample': trial.suggest_float('subsample', 0.01, 1.0, log=True),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.01, 1.0, log=True),\n",
        "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0),\n",
        "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0),\n",
        "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 1.5),\n",
        "        'eval_metric': 'aucpr'\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBClassifier(**params)\n",
        "    #model.fit(X_train_tfidf, y_train)\n",
        "    #predictions_xgb = model.predict(X_test_tfidf)\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "    scores = cross_val_score(model, X_train_tfidf, y_train, cv=skf, scoring='roc_auc')\n",
        "    #roc_auc = roc_auc_score(y_test, predictions_xgb)\n",
        "    return np.mean(scores)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Optuna study and optimize the objective function\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=40)\n",
        "\n",
        "# Get the best hyperparameters and best F1 score\n",
        "best_params = study.best_params\n",
        "best_score = study.best_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg94eIzpFfCT",
        "outputId": "29a6952c-76da-453e-d74b-1442e9ab96ef"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 00:00:48,280] A new study created in memory with name: no-name-47f82504-f3f2-411e-acb0-46866ad6d212\n",
            "[I 2024-03-31 00:01:16,088] Trial 0 finished with value: 0.6528176846033512 and parameters: {'max_depth': 8, 'learning_rate': 0.1642879431555242, 'n_estimators': 133, 'min_child_weight': 15, 'gamma': 2.263878282847891e-06, 'subsample': 0.018626530668443927, 'colsample_bytree': 0.6414282877689742, 'alpha': 0.033355065434607666, 'lambda': 0.2592605569079477, 'scale_pos_weight': 1.4690976496651253}. Best is trial 0 with value: 0.6528176846033512.\n",
            "[I 2024-03-31 00:01:49,532] Trial 1 finished with value: 0.7574110131013683 and parameters: {'max_depth': 8, 'learning_rate': 0.3024398547571826, 'n_estimators': 115, 'min_child_weight': 10, 'gamma': 0.00423891040517043, 'subsample': 0.08692694589200822, 'colsample_bytree': 0.10659658800109034, 'alpha': 0.285826292712869, 'lambda': 0.6679386997318936, 'scale_pos_weight': 1.2217118971401546}. Best is trial 1 with value: 0.7574110131013683.\n",
            "[I 2024-03-31 00:02:42,974] Trial 2 finished with value: 0.7099208609386842 and parameters: {'max_depth': 9, 'learning_rate': 0.3520063507893917, 'n_estimators': 154, 'min_child_weight': 5, 'gamma': 4.6495690700007094e-07, 'subsample': 0.02940414519131162, 'colsample_bytree': 0.3240538762872235, 'alpha': 0.30379634765115354, 'lambda': 0.5701615238410566, 'scale_pos_weight': 1.381978854252318}. Best is trial 1 with value: 0.7574110131013683.\n",
            "[I 2024-03-31 00:03:12,446] Trial 3 finished with value: 0.6759263668926204 and parameters: {'max_depth': 4, 'learning_rate': 0.30370854914746914, 'n_estimators': 134, 'min_child_weight': 8, 'gamma': 1.698594208744305e-07, 'subsample': 0.014559493194313154, 'colsample_bytree': 0.902639836366944, 'alpha': 0.4404048458171732, 'lambda': 0.3157574791426439, 'scale_pos_weight': 1.417185695434193}. Best is trial 1 with value: 0.7574110131013683.\n",
            "[I 2024-03-31 00:03:31,135] Trial 4 finished with value: 0.7039719109069582 and parameters: {'max_depth': 6, 'learning_rate': 0.2823695071267055, 'n_estimators': 146, 'min_child_weight': 8, 'gamma': 2.0800206510715015e-06, 'subsample': 0.030354277760776698, 'colsample_bytree': 0.0169824652200888, 'alpha': 0.3010578978126203, 'lambda': 0.35951974828280797, 'scale_pos_weight': 1.3470662280410006}. Best is trial 1 with value: 0.7574110131013683.\n",
            "[I 2024-03-31 00:03:53,103] Trial 5 finished with value: 0.7480970636917067 and parameters: {'max_depth': 5, 'learning_rate': 0.6504785991199868, 'n_estimators': 135, 'min_child_weight': 10, 'gamma': 1.3759942415951932e-08, 'subsample': 0.12954361697893055, 'colsample_bytree': 0.0658925910431195, 'alpha': 0.1415801385007347, 'lambda': 0.1357061349748329, 'scale_pos_weight': 1.4128969479733717}. Best is trial 1 with value: 0.7574110131013683.\n",
            "[I 2024-03-31 00:04:05,641] Trial 6 finished with value: 0.6057980129023474 and parameters: {'max_depth': 7, 'learning_rate': 0.7940093761767243, 'n_estimators': 166, 'min_child_weight': 11, 'gamma': 9.252156135806868e-05, 'subsample': 0.01600147016577156, 'colsample_bytree': 0.11290877082434582, 'alpha': 0.5580868217455788, 'lambda': 0.4728820156553483, 'scale_pos_weight': 1.0157794119663741}. Best is trial 1 with value: 0.7574110131013683.\n",
            "[I 2024-03-31 00:04:32,764] Trial 7 finished with value: 0.828568750565833 and parameters: {'max_depth': 5, 'learning_rate': 0.2083068611303904, 'n_estimators': 98, 'min_child_weight': 10, 'gamma': 0.035128714021148914, 'subsample': 0.8474579904774844, 'colsample_bytree': 0.1388552712188098, 'alpha': 0.08870402471114047, 'lambda': 0.9186017727261143, 'scale_pos_weight': 1.1333563112147036}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:05:12,802] Trial 8 finished with value: 0.6469921558047329 and parameters: {'max_depth': 9, 'learning_rate': 0.9742912942334003, 'n_estimators': 98, 'min_child_weight': 2, 'gamma': 1.6402237417398143e-05, 'subsample': 0.029387682738396235, 'colsample_bytree': 0.4850071283799727, 'alpha': 0.7913175822215885, 'lambda': 0.2715927559599179, 'scale_pos_weight': 1.3112725957972309}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:05:32,459] Trial 9 finished with value: 0.707711295628903 and parameters: {'max_depth': 8, 'learning_rate': 0.4823486899608307, 'n_estimators': 148, 'min_child_weight': 13, 'gamma': 0.16877040412080804, 'subsample': 0.0431808113351084, 'colsample_bytree': 0.03439805943349679, 'alpha': 0.238481002868686, 'lambda': 0.5575610437515134, 'scale_pos_weight': 1.396352111855736}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:05:49,367] Trial 10 finished with value: 0.798050937414047 and parameters: {'max_depth': 4, 'learning_rate': 0.1374550018537663, 'n_estimators': 59, 'min_child_weight': 5, 'gamma': 0.3538997632075017, 'subsample': 0.978099727612968, 'colsample_bytree': 0.21347893099435106, 'alpha': 0.9799107013226636, 'lambda': 0.9883410618991204, 'scale_pos_weight': 1.1358676768374825}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:06:04,467] Trial 11 finished with value: 0.7940682418974417 and parameters: {'max_depth': 4, 'learning_rate': 0.13478069733820508, 'n_estimators': 53, 'min_child_weight': 5, 'gamma': 0.6913509294211789, 'subsample': 0.8569621024712726, 'colsample_bytree': 0.22018682421268776, 'alpha': 0.9740303761441881, 'lambda': 0.8810503878482364, 'scale_pos_weight': 1.1351502835243241}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:06:28,681] Trial 12 finished with value: 0.8013175676167836 and parameters: {'max_depth': 5, 'learning_rate': 0.10823816914691281, 'n_estimators': 64, 'min_child_weight': 5, 'gamma': 0.009477706918222995, 'subsample': 0.9525542061342597, 'colsample_bytree': 0.19745187244583326, 'alpha': 0.6806282131383089, 'lambda': 0.9845706900997098, 'scale_pos_weight': 1.1169326708235814}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:06:52,752] Trial 13 finished with value: 0.8112099606858962 and parameters: {'max_depth': 6, 'learning_rate': 0.47361378157949596, 'n_estimators': 79, 'min_child_weight': 1, 'gamma': 0.005840514787303985, 'subsample': 0.3927501184710808, 'colsample_bytree': 0.05384693008372992, 'alpha': 0.6225383955631589, 'lambda': 0.7924471448359984, 'scale_pos_weight': 1.043500840566093}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:07:16,901] Trial 14 finished with value: 0.8010982454374707 and parameters: {'max_depth': 6, 'learning_rate': 0.5172412639328007, 'n_estimators': 85, 'min_child_weight': 1, 'gamma': 0.003553186926161585, 'subsample': 0.383043440635639, 'colsample_bytree': 0.040575094114054785, 'alpha': 0.5304851279790933, 'lambda': 0.7787023581885989, 'scale_pos_weight': 1.0020121534772386}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:07:31,732] Trial 15 finished with value: 0.7433939609261637 and parameters: {'max_depth': 5, 'learning_rate': 0.6638714779999395, 'n_estimators': 82, 'min_child_weight': 3, 'gamma': 0.02211951437773995, 'subsample': 0.3470419929734496, 'colsample_bytree': 0.012153843515927047, 'alpha': 0.7154137411981902, 'lambda': 0.8247787834084446, 'scale_pos_weight': 1.0754193646240258}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:07:58,617] Trial 16 finished with value: 0.8054802582635986 and parameters: {'max_depth': 6, 'learning_rate': 0.40943590396947915, 'n_estimators': 110, 'min_child_weight': 7, 'gamma': 0.0005804470721341897, 'subsample': 0.355445084212809, 'colsample_bytree': 0.05598655510984161, 'alpha': 0.014343188151087816, 'lambda': 0.705943059335377, 'scale_pos_weight': 1.2159981030136935}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:08:15,188] Trial 17 finished with value: 0.7282712654239775 and parameters: {'max_depth': 7, 'learning_rate': 0.6267315656683411, 'n_estimators': 77, 'min_child_weight': 12, 'gamma': 0.0607574120793589, 'subsample': 0.16800850079051713, 'colsample_bytree': 0.017974910273962127, 'alpha': 0.42466279347816616, 'lambda': 0.8780632402331057, 'scale_pos_weight': 1.0620336712884635}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:08:36,586] Trial 18 finished with value: 0.8015422851962329 and parameters: {'max_depth': 5, 'learning_rate': 0.7745400657745534, 'n_estimators': 100, 'min_child_weight': 13, 'gamma': 0.0006406536449416109, 'subsample': 0.6037026413341119, 'colsample_bytree': 0.08395719773702708, 'alpha': 0.8524513349183438, 'lambda': 0.6827434142160379, 'scale_pos_weight': 1.1794921457444418}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:08:53,847] Trial 19 finished with value: 0.752669480589679 and parameters: {'max_depth': 7, 'learning_rate': 0.2318916200325912, 'n_estimators': 73, 'min_child_weight': 15, 'gamma': 0.0007458717823544812, 'subsample': 0.218999206070433, 'colsample_bytree': 0.03060909483861842, 'alpha': 0.6594068582946271, 'lambda': 0.9236411281294179, 'scale_pos_weight': 1.275044751801821}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:09:25,354] Trial 20 finished with value: 0.7609009174603869 and parameters: {'max_depth': 6, 'learning_rate': 0.4337150068585424, 'n_estimators': 121, 'min_child_weight': 3, 'gamma': 0.059567417179879435, 'subsample': 0.08121592801142095, 'colsample_bytree': 0.13349383926176492, 'alpha': 0.39789782691394776, 'lambda': 0.7455036610553742, 'scale_pos_weight': 1.071358980045046}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:09:48,857] Trial 21 finished with value: 0.8136224155847895 and parameters: {'max_depth': 6, 'learning_rate': 0.40230483491551816, 'n_estimators': 97, 'min_child_weight': 7, 'gamma': 0.00034303745116670065, 'subsample': 0.4406962584519479, 'colsample_bytree': 0.05673692737654614, 'alpha': 0.044669820694413775, 'lambda': 0.6347753304905428, 'scale_pos_weight': 1.228281683606186}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:10:09,397] Trial 22 finished with value: 0.8138116227916544 and parameters: {'max_depth': 5, 'learning_rate': 0.39394966725702807, 'n_estimators': 95, 'min_child_weight': 7, 'gamma': 8.773679125538314e-05, 'subsample': 0.5453887641244773, 'colsample_bytree': 0.049645296611444636, 'alpha': 0.12744555705900298, 'lambda': 0.6238085452653345, 'scale_pos_weight': 1.1810772922449289}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:10:26,743] Trial 23 finished with value: 0.8065197997244443 and parameters: {'max_depth': 5, 'learning_rate': 0.3766367888282092, 'n_estimators': 96, 'min_child_weight': 7, 'gamma': 4.148442003649635e-05, 'subsample': 0.5508526393870558, 'colsample_bytree': 0.028070834238734535, 'alpha': 0.1348493032367377, 'lambda': 0.4731858253621739, 'scale_pos_weight': 1.1857843895281872}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:10:48,634] Trial 24 finished with value: 0.8205523367706151 and parameters: {'max_depth': 5, 'learning_rate': 0.22100141623896216, 'n_estimators': 94, 'min_child_weight': 9, 'gamma': 7.89872252178086e-06, 'subsample': 0.602079172722993, 'colsample_bytree': 0.07070123940866671, 'alpha': 0.14547540879131537, 'lambda': 0.6018050753451246, 'scale_pos_weight': 1.2705370640422267}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:11:09,069] Trial 25 finished with value: 0.8235804923370365 and parameters: {'max_depth': 4, 'learning_rate': 0.2140620247380945, 'n_estimators': 91, 'min_child_weight': 9, 'gamma': 1.0064489679002017e-05, 'subsample': 0.6230387966326258, 'colsample_bytree': 0.16185897474587424, 'alpha': 0.15826495463054419, 'lambda': 0.4134837457600149, 'scale_pos_weight': 1.2739272890891657}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:11:25,382] Trial 26 finished with value: 0.8042434458295368 and parameters: {'max_depth': 4, 'learning_rate': 0.22967918102176882, 'n_estimators': 89, 'min_child_weight': 10, 'gamma': 1.410348271225527e-05, 'subsample': 0.25169714514405267, 'colsample_bytree': 0.1532348004307245, 'alpha': 0.20524626221539177, 'lambda': 0.40806105753120964, 'scale_pos_weight': 1.2777058668513375}. Best is trial 7 with value: 0.828568750565833.\n",
            "[I 2024-03-31 00:11:57,331] Trial 27 finished with value: 0.830495758881694 and parameters: {'max_depth': 4, 'learning_rate': 0.24139569331004776, 'n_estimators': 106, 'min_child_weight': 9, 'gamma': 2.789113549222612e-06, 'subsample': 0.6715717005082222, 'colsample_bytree': 0.31422107747166034, 'alpha': 0.09727944831176341, 'lambda': 0.038767238984813934, 'scale_pos_weight': 1.3083916234123234}. Best is trial 27 with value: 0.830495758881694.\n",
            "[I 2024-03-31 00:12:23,133] Trial 28 finished with value: 0.8063416811014429 and parameters: {'max_depth': 4, 'learning_rate': 0.19784861564279183, 'n_estimators': 108, 'min_child_weight': 12, 'gamma': 4.211184696299733e-08, 'subsample': 0.2535782684110241, 'colsample_bytree': 0.34033279692025425, 'alpha': 0.08697214074436138, 'lambda': 0.01981613222822995, 'scale_pos_weight': 1.3438801364765114}. Best is trial 27 with value: 0.830495758881694.\n",
            "[I 2024-03-31 00:13:08,601] Trial 29 finished with value: 0.8360882428463118 and parameters: {'max_depth': 4, 'learning_rate': 0.28199135040568024, 'n_estimators': 125, 'min_child_weight': 9, 'gamma': 2.123613971595966e-06, 'subsample': 0.7235722071007992, 'colsample_bytree': 0.39753980358645963, 'alpha': 0.014221655429514979, 'lambda': 0.1820442786535955, 'scale_pos_weight': 1.4714525060493737}. Best is trial 29 with value: 0.8360882428463118.\n",
            "[I 2024-03-31 00:13:24,841] Trial 30 finished with value: 0.618149388302429 and parameters: {'max_depth': 4, 'learning_rate': 0.3143871765346442, 'n_estimators': 127, 'min_child_weight': 11, 'gamma': 1.475445935589397e-06, 'subsample': 0.0102963200372203, 'colsample_bytree': 0.5653034171093851, 'alpha': 0.00995291871512337, 'lambda': 0.16492743173350766, 'scale_pos_weight': 1.497682564033026}. Best is trial 29 with value: 0.8360882428463118.\n",
            "[I 2024-03-31 00:13:57,136] Trial 31 finished with value: 0.8283884040259526 and parameters: {'max_depth': 4, 'learning_rate': 0.18439909505885307, 'n_estimators': 107, 'min_child_weight': 9, 'gamma': 4.3643043320422714e-07, 'subsample': 0.7346960671987401, 'colsample_bytree': 0.32254054390979897, 'alpha': 0.19580787659328122, 'lambda': 0.0045075081845010745, 'scale_pos_weight': 1.4361688245429014}. Best is trial 29 with value: 0.8360882428463118.\n",
            "[I 2024-03-31 00:14:34,738] Trial 32 finished with value: 0.8274979632184177 and parameters: {'max_depth': 4, 'learning_rate': 0.16963650612361933, 'n_estimators': 118, 'min_child_weight': 9, 'gamma': 2.598046817765804e-07, 'subsample': 0.7719415463515862, 'colsample_bytree': 0.3189313926776897, 'alpha': 0.08493836653147645, 'lambda': 0.004000512532076794, 'scale_pos_weight': 1.4507361848561755}. Best is trial 29 with value: 0.8360882428463118.\n",
            "[I 2024-03-31 00:15:11,812] Trial 33 finished with value: 0.8344087085175337 and parameters: {'max_depth': 4, 'learning_rate': 0.283010794717198, 'n_estimators': 107, 'min_child_weight': 11, 'gamma': 7.675827241033361e-07, 'subsample': 0.7750618566104119, 'colsample_bytree': 0.4224513692952069, 'alpha': 0.22568395607935712, 'lambda': 0.11997766691196679, 'scale_pos_weight': 1.4603996139103743}. Best is trial 29 with value: 0.8360882428463118.\n",
            "[I 2024-03-31 00:16:05,735] Trial 34 finished with value: 0.8242387630935726 and parameters: {'max_depth': 4, 'learning_rate': 0.27580157322063226, 'n_estimators': 115, 'min_child_weight': 14, 'gamma': 9.969458916777376e-08, 'subsample': 0.46621817702776114, 'colsample_bytree': 0.9083324053092561, 'alpha': 0.33871400161443943, 'lambda': 0.11233983317612904, 'scale_pos_weight': 1.4988945702819196}. Best is trial 29 with value: 0.8360882428463118.\n",
            "[I 2024-03-31 00:16:46,842] Trial 35 finished with value: 0.8049413741985887 and parameters: {'max_depth': 5, 'learning_rate': 0.3462810881542542, 'n_estimators': 124, 'min_child_weight': 11, 'gamma': 1.1760376860096788e-06, 'subsample': 0.2966443548014784, 'colsample_bytree': 0.43433863819937124, 'alpha': 0.24430388186607344, 'lambda': 0.214043244981664, 'scale_pos_weight': 1.3647372124196964}. Best is trial 29 with value: 0.8360882428463118.\n",
            "[I 2024-03-31 00:18:01,782] Trial 36 finished with value: 0.8379430390269655 and parameters: {'max_depth': 4, 'learning_rate': 0.29590912738331954, 'n_estimators': 137, 'min_child_weight': 10, 'gamma': 3.877924824268651e-06, 'subsample': 0.7321811649758878, 'colsample_bytree': 0.6775671894875651, 'alpha': 0.06700696661440605, 'lambda': 0.07700543018836516, 'scale_pos_weight': 1.4600592103189587}. Best is trial 36 with value: 0.8379430390269655.\n",
            "[I 2024-03-31 00:18:37,185] Trial 37 finished with value: 0.766759681880966 and parameters: {'max_depth': 4, 'learning_rate': 0.2888170184384319, 'n_estimators': 140, 'min_child_weight': 8, 'gamma': 3.3502225380404246e-06, 'subsample': 0.07346517493551517, 'colsample_bytree': 0.7554488187830559, 'alpha': 0.06186482522595633, 'lambda': 0.08051538583238238, 'scale_pos_weight': 1.4667805545543504}. Best is trial 36 with value: 0.8379430390269655.\n",
            "[I 2024-03-31 00:19:18,632] Trial 38 finished with value: 0.7683792879862482 and parameters: {'max_depth': 4, 'learning_rate': 0.5821912785281459, 'n_estimators': 160, 'min_child_weight': 12, 'gamma': 7.36724869405321e-07, 'subsample': 0.1677043976762017, 'colsample_bytree': 0.683764720012345, 'alpha': 0.3477679522866943, 'lambda': 0.2006809837417615, 'scale_pos_weight': 1.4166267965220118}. Best is trial 36 with value: 0.8379430390269655.\n",
            "[I 2024-03-31 00:20:23,338] Trial 39 finished with value: 0.8359281586413377 and parameters: {'max_depth': 5, 'learning_rate': 0.3364166198907222, 'n_estimators': 129, 'min_child_weight': 6, 'gamma': 4.3141524296503615e-06, 'subsample': 0.7015859266909525, 'colsample_bytree': 0.39971429581186263, 'alpha': 0.0019805148043204324, 'lambda': 0.06064937933107049, 'scale_pos_weight': 1.4734286057087584}. Best is trial 36 with value: 0.8379430390269655.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_params)\n",
        "print(best_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUkp5eD-NOoA",
        "outputId": "698d35c4-11e7-4ff4-ffaf-0533219dde5c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 4, 'learning_rate': 0.29590912738331954, 'n_estimators': 137, 'min_child_weight': 10, 'gamma': 3.877924824268651e-06, 'subsample': 0.7321811649758878, 'colsample_bytree': 0.6775671894875651, 'alpha': 0.06700696661440605, 'lambda': 0.07700543018836516, 'scale_pos_weight': 1.4600592103189587}\n",
            "0.8379430390269655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "qriGLNj6pzWw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "085fdc97-7ea0-4991-c182-430bac7bc79e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 4, 'learning_rate': 0.29590912738331954, 'n_estimators': 137, 'min_child_weight': 10, 'gamma': 3.877924824268651e-06, 'subsample': 0.7321811649758878, 'colsample_bytree': 0.6775671894875651, 'alpha': 0.06700696661440605, 'lambda': 0.07700543018836516, 'scale_pos_weight': 1.4600592103189587}\n",
            "0.8379430390269655\n"
          ]
        }
      ],
      "source": [
        "print(best_params)\n",
        "print(best_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "icVi5Elw0U7k"
      },
      "outputs": [],
      "source": [
        "best_model = xgb.XGBClassifier(**best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "2T4FOL0mS_YM",
        "outputId": "a3e148c6-8409-493c-a31c-5dce7f1d67f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score:0.7766\n",
            "Balanced accuracy score:0.7569\n",
            "F-1 score:0.7043\n",
            "ROC-AUC score:0.7569\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "best_model.fit(X_train_tfidf, y_train)\n",
        "predictions_best = best_model.predict(X_test_tfidf)\n",
        "predictions_best_proba_train = best_model.predict_proba(X_train_tfidf)[:, 1]\n",
        "predictions_best_proba_test = best_model.predict_proba(X_test_tfidf)[:, 1]\n",
        "\n",
        "eval_report(y_test, predictions_best)\n",
        "cm = confusion_matrix(y_test, predictions_best)\n",
        "confusion_matrix_visualization(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "hEs8cxVdPIDl"
      },
      "outputs": [],
      "source": [
        "best_model.save_model('/content/gdrive/My Drive/models_fake_news/xgboost_best_model_cv_tfidf.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "JABRblPo7912"
      },
      "outputs": [],
      "source": [
        "def to_labels(pos_probs, threshold):\n",
        "    return (pos_probs >= threshold).astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "uxsQcvLK6U2E"
      },
      "outputs": [],
      "source": [
        "### return threshold where F1-score is the biggest\n",
        "def best_tresholds_f1(y_pred_proba, y_test):\n",
        "    # define thresholds\n",
        "    thresholds = np.arange(0, 1, 0.001)\n",
        "    # evaluate each threshold\n",
        "    scores = [metrics.f1_score(y_test, to_labels(y_pred_proba, t)) for t in thresholds]\n",
        "    # get best threshold\n",
        "    ix = np.argmax(scores)\n",
        "    #print('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))\n",
        "    return thresholds[ix], scores[ix]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWUgtASH6gC_",
        "outputId": "6237ce07-bdd8-4566-882e-7e25f035971c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.7358, treshold: 0.447\n"
          ]
        }
      ],
      "source": [
        "treshold_f1 = best_tresholds_f1(predictions_best_proba_train, y_train)\n",
        "print(f'F1 score: {treshold_f1[1]:.4f}, treshold: {treshold_f1[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHSE0tVvEWFP",
        "outputId": "9dcf9fc5-a8c9-42cf-e4ac-40cf680775d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6846636509557859"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "y_pred_463 = to_labels(predictions_best_proba_test, 0.37) #threshold = 0.463\n",
        "metrics.f1_score(y_test, y_pred_463)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YUS0A2rbSOz"
      },
      "source": [
        "LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "zrJBXj26CoYD"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "pcYFgbvHizNh",
        "outputId": "8dbca8ee-fd1a-48ef-c06d-0b86e9534ed2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 20707, number of negative: 28390\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.693051 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 266930\n",
            "[LightGBM] [Info] Number of data points in the train set: 49097, number of used features: 3489\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421757 -> initscore=-0.315565\n",
            "[LightGBM] [Info] Start training from score -0.315565\n",
            "Accuracy score:0.7968\n",
            "Balanced accuracy score:0.7663\n",
            "F-1 score:0.7027\n",
            "ROC-AUC score:0.7663\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_lgb = lgb.LGBMClassifier()\n",
        "model_lgb.fit(X_train_tfidf, y_train)\n",
        "predictions_lgb = model_lgb.predict(X_test_tfidf)\n",
        "\n",
        "eval_report(y_test, predictions_lgb)\n",
        "cm = confusion_matrix(y_test, predictions_lgb)\n",
        "confusion_matrix_visualization(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytq_-reSFAtz",
        "outputId": "bf24b619-331c-4c38-85d0-3c88e59e48a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/models_fake_news/model_lgb.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "joblib.dump(model_lgb, '/content/gdrive/My Drive/models_fake_news/model_lgb.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqjwzvFSCMYz",
        "outputId": "5fe96116-fa7b-462c-f694-e2229c36a906"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightgbm.basic.Booster at 0x7dc1ba151870>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "model_lgb.booster_.save_model('/content/gdrive/My Drive/models_fake_news/model_lgb.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJcj0Aux99LT"
      },
      "source": [
        "LightGBM + OPTUNA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "B9U91l0wkHSu"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'average_precision',\n",
        "        'boosting_type': 'gbdt',\n",
        "\t\t    'num_iteration': trial.suggest_int('num_leaves', 70, 150),\n",
        "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
        "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 2, 100),\n",
        "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
        "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 0, 10),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_child_samples', 1, 100),\n",
        "        'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced']),\n",
        "    }\n",
        "\n",
        "    model = lgb.LGBMClassifier(**params)\n",
        "    #model.fit(X_train_tfidf, y_train)\n",
        "    #predictions_xgb = model.predict(X_test_tfidf)'\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "    scores = cross_val_score(model, X_train_tfidf, y_train, cv=skf, scoring='roc_auc')\n",
        "    #roc_auc = roc_auc_score(y_test, predictions_xgb)\n",
        "    return np.mean(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6efM8sxvBs8r",
        "outputId": "13fb3918-6b27-4aba-b5ab-bd04e777b843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 00:25:40,220] A new study created in memory with name: no-name-b11e5eae-cba5-4121-a7c4-4c0f166bfb85\n",
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9950022404016701, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950022404016701\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.348035985208907e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.348035985208907e-07\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.31821501765176674, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31821501765176674\n",
            "[LightGBM] [Warning] num_iterations is set=86, num_iteration=86 will be ignored. Current value: num_iterations=86\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6343385417461256, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6343385417461256\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950022404016701, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950022404016701\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.348035985208907e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.348035985208907e-07\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.31821501765176674, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31821501765176674\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6343385417461256, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6343385417461256\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.649377 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 214796\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 2574\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950022404016701, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950022404016701\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.348035985208907e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.348035985208907e-07\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.31821501765176674, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31821501765176674\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6343385417461256, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6343385417461256\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950022404016701, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950022404016701\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.348035985208907e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.348035985208907e-07\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.31821501765176674, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31821501765176674\n",
            "[LightGBM] [Warning] num_iterations is set=86, num_iteration=86 will be ignored. Current value: num_iterations=86\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6343385417461256, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6343385417461256\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950022404016701, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950022404016701\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.348035985208907e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.348035985208907e-07\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.31821501765176674, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31821501765176674\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6343385417461256, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6343385417461256\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.660889 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 213392\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 2547\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950022404016701, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950022404016701\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.348035985208907e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.348035985208907e-07\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.31821501765176674, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31821501765176674\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6343385417461256, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6343385417461256\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950022404016701, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950022404016701\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.348035985208907e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.348035985208907e-07\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.31821501765176674, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31821501765176674\n",
            "[LightGBM] [Warning] num_iterations is set=86, num_iteration=86 will be ignored. Current value: num_iterations=86\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6343385417461256, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6343385417461256\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950022404016701, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950022404016701\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.348035985208907e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.348035985208907e-07\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.31821501765176674, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31821501765176674\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6343385417461256, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6343385417461256\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.708029 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 214674\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2563\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950022404016701, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950022404016701\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.348035985208907e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.348035985208907e-07\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.31821501765176674, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31821501765176674\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6343385417461256, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6343385417461256\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950022404016701, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950022404016701\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.348035985208907e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.348035985208907e-07\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.31821501765176674, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31821501765176674\n",
            "[LightGBM] [Warning] num_iterations is set=86, num_iteration=86 will be ignored. Current value: num_iterations=86\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6343385417461256, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6343385417461256\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950022404016701, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950022404016701\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.348035985208907e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.348035985208907e-07\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.31821501765176674, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31821501765176674\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6343385417461256, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6343385417461256\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.125875 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 213726\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2553\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950022404016701, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950022404016701\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.348035985208907e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.348035985208907e-07\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.31821501765176674, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31821501765176674\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6343385417461256, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6343385417461256\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950022404016701, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950022404016701\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.348035985208907e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.348035985208907e-07\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.31821501765176674, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31821501765176674\n",
            "[LightGBM] [Warning] num_iterations is set=86, num_iteration=86 will be ignored. Current value: num_iterations=86\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6343385417461256, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6343385417461256\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950022404016701, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950022404016701\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.348035985208907e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.348035985208907e-07\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.31821501765176674, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31821501765176674\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6343385417461256, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6343385417461256\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.614151 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 213867\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2559\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 00:28:06,139] Trial 0 finished with value: 0.8218578522252493 and parameters: {'num_leaves': 86, 'lambda_l1': 0.31821501765176674, 'lambda_l2': 1.348035985208907e-07, 'feature_fraction': 0.9950022404016701, 'bagging_fraction': 0.6343385417461256, 'bagging_freq': 3, 'min_child_samples': 54, 'class_weight': None}. Best is trial 0 with value: 0.8218578522252493.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=54, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=54\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9950022404016701, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9950022404016701\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.348035985208907e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.348035985208907e-07\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.31821501765176674, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31821501765176674\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6343385417461256, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6343385417461256\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8025661172613511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8025661172613511\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4239983352561993e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4239983352561993e-06\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.097676742716628e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.097676742716628e-05\n",
            "[LightGBM] [Warning] num_iterations is set=118, num_iteration=118 will be ignored. Current value: num_iterations=118\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3493115591656881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3493115591656881\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8025661172613511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8025661172613511\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4239983352561993e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4239983352561993e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.097676742716628e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.097676742716628e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3493115591656881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3493115591656881\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.058606 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 227761\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3440\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8025661172613511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8025661172613511\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4239983352561993e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4239983352561993e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.097676742716628e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.097676742716628e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3493115591656881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3493115591656881\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8025661172613511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8025661172613511\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4239983352561993e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4239983352561993e-06\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.097676742716628e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.097676742716628e-05\n",
            "[LightGBM] [Warning] num_iterations is set=118, num_iteration=118 will be ignored. Current value: num_iterations=118\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3493115591656881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3493115591656881\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8025661172613511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8025661172613511\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4239983352561993e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4239983352561993e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.097676742716628e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.097676742716628e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3493115591656881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3493115591656881\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.255075 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 226570\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3431\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8025661172613511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8025661172613511\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4239983352561993e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4239983352561993e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.097676742716628e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.097676742716628e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3493115591656881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3493115591656881\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8025661172613511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8025661172613511\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4239983352561993e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4239983352561993e-06\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.097676742716628e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.097676742716628e-05\n",
            "[LightGBM] [Warning] num_iterations is set=118, num_iteration=118 will be ignored. Current value: num_iterations=118\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3493115591656881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3493115591656881\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8025661172613511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8025661172613511\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4239983352561993e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4239983352561993e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.097676742716628e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.097676742716628e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3493115591656881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3493115591656881\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.019050 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 227776\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3435\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8025661172613511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8025661172613511\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4239983352561993e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4239983352561993e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.097676742716628e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.097676742716628e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3493115591656881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3493115591656881\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8025661172613511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8025661172613511\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4239983352561993e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4239983352561993e-06\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.097676742716628e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.097676742716628e-05\n",
            "[LightGBM] [Warning] num_iterations is set=118, num_iteration=118 will be ignored. Current value: num_iterations=118\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3493115591656881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3493115591656881\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8025661172613511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8025661172613511\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4239983352561993e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4239983352561993e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.097676742716628e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.097676742716628e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3493115591656881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3493115591656881\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.032712 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 226940\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3434\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8025661172613511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8025661172613511\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4239983352561993e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4239983352561993e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.097676742716628e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.097676742716628e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3493115591656881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3493115591656881\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8025661172613511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8025661172613511\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4239983352561993e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4239983352561993e-06\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.097676742716628e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.097676742716628e-05\n",
            "[LightGBM] [Warning] num_iterations is set=118, num_iteration=118 will be ignored. Current value: num_iterations=118\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3493115591656881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3493115591656881\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8025661172613511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8025661172613511\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4239983352561993e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4239983352561993e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.097676742716628e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.097676742716628e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3493115591656881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3493115591656881\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.017810 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 226928\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3434\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8025661172613511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8025661172613511\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4239983352561993e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4239983352561993e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.097676742716628e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.097676742716628e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.3493115591656881, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3493115591656881\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 00:32:11,680] Trial 1 finished with value: 0.7995618390390119 and parameters: {'num_leaves': 118, 'lambda_l1': 3.097676742716628e-05, 'lambda_l2': 1.4239983352561993e-06, 'feature_fraction': 0.8025661172613511, 'bagging_fraction': 0.3493115591656881, 'bagging_freq': 1, 'min_child_samples': 28, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.8218578522252493.\n",
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.14008530583585546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.14008530583585546\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03930375772437914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03930375772437914\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.635294178740637e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.635294178740637e-08\n",
            "[LightGBM] [Warning] num_iterations is set=131, num_iteration=131 will be ignored. Current value: num_iterations=131\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19576251287698293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19576251287698293\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.14008530583585546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.14008530583585546\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03930375772437914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03930375772437914\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.635294178740637e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.635294178740637e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19576251287698293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19576251287698293\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.852652 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 224536\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3181\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.14008530583585546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.14008530583585546\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03930375772437914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03930375772437914\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.635294178740637e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.635294178740637e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19576251287698293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19576251287698293\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.14008530583585546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.14008530583585546\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03930375772437914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03930375772437914\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.635294178740637e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.635294178740637e-08\n",
            "[LightGBM] [Warning] num_iterations is set=131, num_iteration=131 will be ignored. Current value: num_iterations=131\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19576251287698293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19576251287698293\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.14008530583585546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.14008530583585546\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03930375772437914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03930375772437914\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.635294178740637e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.635294178740637e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19576251287698293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19576251287698293\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.916878 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 223379\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3172\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.14008530583585546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.14008530583585546\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03930375772437914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03930375772437914\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.635294178740637e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.635294178740637e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19576251287698293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19576251287698293\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.14008530583585546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.14008530583585546\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03930375772437914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03930375772437914\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.635294178740637e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.635294178740637e-08\n",
            "[LightGBM] [Warning] num_iterations is set=131, num_iteration=131 will be ignored. Current value: num_iterations=131\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19576251287698293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19576251287698293\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.14008530583585546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.14008530583585546\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03930375772437914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03930375772437914\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.635294178740637e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.635294178740637e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19576251287698293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19576251287698293\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.986209 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 224905\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3204\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.14008530583585546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.14008530583585546\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03930375772437914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03930375772437914\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.635294178740637e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.635294178740637e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19576251287698293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19576251287698293\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.14008530583585546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.14008530583585546\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03930375772437914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03930375772437914\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.635294178740637e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.635294178740637e-08\n",
            "[LightGBM] [Warning] num_iterations is set=131, num_iteration=131 will be ignored. Current value: num_iterations=131\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19576251287698293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19576251287698293\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.14008530583585546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.14008530583585546\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03930375772437914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03930375772437914\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.635294178740637e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.635294178740637e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19576251287698293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19576251287698293\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.347492 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 223514\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3159\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.14008530583585546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.14008530583585546\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03930375772437914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03930375772437914\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.635294178740637e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.635294178740637e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19576251287698293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19576251287698293\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.14008530583585546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.14008530583585546\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03930375772437914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03930375772437914\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.635294178740637e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.635294178740637e-08\n",
            "[LightGBM] [Warning] num_iterations is set=131, num_iteration=131 will be ignored. Current value: num_iterations=131\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19576251287698293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19576251287698293\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.14008530583585546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.14008530583585546\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03930375772437914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03930375772437914\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.635294178740637e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.635294178740637e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19576251287698293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19576251287698293\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.886986 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 223629\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3167\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
            "[LightGBM] [Warning] feature_fraction is set=0.14008530583585546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.14008530583585546\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03930375772437914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03930375772437914\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.635294178740637e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.635294178740637e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.19576251287698293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.19576251287698293\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 00:33:00,493] Trial 2 finished with value: 0.7804951609353978 and parameters: {'num_leaves': 131, 'lambda_l1': 5.635294178740637e-08, 'lambda_l2': 0.03930375772437914, 'feature_fraction': 0.14008530583585546, 'bagging_fraction': 0.19576251287698293, 'bagging_freq': 8, 'min_child_samples': 38, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.8218578522252493.\n",
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8881230462440608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8881230462440608\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002075241544571056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002075241544571056\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.011586740538540625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011586740538540625\n",
            "[LightGBM] [Warning] num_iterations is set=126, num_iteration=126 will be ignored. Current value: num_iterations=126\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8849617108179018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8849617108179018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8881230462440608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8881230462440608\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002075241544571056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002075241544571056\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.011586740538540625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011586740538540625\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8849617108179018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8849617108179018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.582186 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 210111\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 2341\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8881230462440608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8881230462440608\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002075241544571056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002075241544571056\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.011586740538540625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011586740538540625\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8849617108179018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8849617108179018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8881230462440608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8881230462440608\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002075241544571056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002075241544571056\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.011586740538540625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011586740538540625\n",
            "[LightGBM] [Warning] num_iterations is set=126, num_iteration=126 will be ignored. Current value: num_iterations=126\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8849617108179018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8849617108179018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8881230462440608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8881230462440608\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002075241544571056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002075241544571056\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.011586740538540625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011586740538540625\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8849617108179018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8849617108179018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.585323 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 209390\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 2348\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8881230462440608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8881230462440608\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002075241544571056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002075241544571056\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.011586740538540625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011586740538540625\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8849617108179018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8849617108179018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8881230462440608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8881230462440608\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002075241544571056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002075241544571056\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.011586740538540625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011586740538540625\n",
            "[LightGBM] [Warning] num_iterations is set=126, num_iteration=126 will be ignored. Current value: num_iterations=126\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8849617108179018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8849617108179018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8881230462440608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8881230462440608\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002075241544571056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002075241544571056\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.011586740538540625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011586740538540625\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8849617108179018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8849617108179018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.955411 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 210601\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2360\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8881230462440608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8881230462440608\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002075241544571056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002075241544571056\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.011586740538540625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011586740538540625\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8849617108179018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8849617108179018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8881230462440608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8881230462440608\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002075241544571056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002075241544571056\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.011586740538540625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011586740538540625\n",
            "[LightGBM] [Warning] num_iterations is set=126, num_iteration=126 will be ignored. Current value: num_iterations=126\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8849617108179018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8849617108179018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8881230462440608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8881230462440608\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002075241544571056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002075241544571056\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.011586740538540625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011586740538540625\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8849617108179018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8849617108179018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.589821 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 209762\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2356\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8881230462440608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8881230462440608\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002075241544571056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002075241544571056\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.011586740538540625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011586740538540625\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8849617108179018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8849617108179018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8881230462440608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8881230462440608\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002075241544571056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002075241544571056\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.011586740538540625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011586740538540625\n",
            "[LightGBM] [Warning] num_iterations is set=126, num_iteration=126 will be ignored. Current value: num_iterations=126\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8849617108179018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8849617108179018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8881230462440608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8881230462440608\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002075241544571056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002075241544571056\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.011586740538540625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011586740538540625\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8849617108179018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8849617108179018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.575459 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 209599\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2346\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8881230462440608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8881230462440608\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002075241544571056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002075241544571056\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.011586740538540625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011586740538540625\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8849617108179018, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8849617108179018\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 00:37:11,908] Trial 3 finished with value: 0.8095068436195041 and parameters: {'num_leaves': 126, 'lambda_l1': 0.011586740538540625, 'lambda_l2': 0.002075241544571056, 'feature_fraction': 0.8881230462440608, 'bagging_fraction': 0.8849617108179018, 'bagging_freq': 6, 'min_child_samples': 62, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.8218578522252493.\n",
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9815153558235846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9815153558235846\n",
            "[LightGBM] [Warning] lambda_l2 is set=5.0813369026330514e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0813369026330514e-06\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.787654837010974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.787654837010974\n",
            "[LightGBM] [Warning] num_iterations is set=113, num_iteration=113 will be ignored. Current value: num_iterations=113\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1543406516103184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1543406516103184\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9815153558235846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9815153558235846\n",
            "[LightGBM] [Warning] lambda_l2 is set=5.0813369026330514e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0813369026330514e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.787654837010974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.787654837010974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1543406516103184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1543406516103184\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.943751 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 225290\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3237\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9815153558235846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9815153558235846\n",
            "[LightGBM] [Warning] lambda_l2 is set=5.0813369026330514e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0813369026330514e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.787654837010974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.787654837010974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1543406516103184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1543406516103184\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9815153558235846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9815153558235846\n",
            "[LightGBM] [Warning] lambda_l2 is set=5.0813369026330514e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0813369026330514e-06\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.787654837010974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.787654837010974\n",
            "[LightGBM] [Warning] num_iterations is set=113, num_iteration=113 will be ignored. Current value: num_iterations=113\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1543406516103184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1543406516103184\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9815153558235846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9815153558235846\n",
            "[LightGBM] [Warning] lambda_l2 is set=5.0813369026330514e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0813369026330514e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.787654837010974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.787654837010974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1543406516103184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1543406516103184\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.919244 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 223960\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3215\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9815153558235846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9815153558235846\n",
            "[LightGBM] [Warning] lambda_l2 is set=5.0813369026330514e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0813369026330514e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.787654837010974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.787654837010974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1543406516103184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1543406516103184\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9815153558235846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9815153558235846\n",
            "[LightGBM] [Warning] lambda_l2 is set=5.0813369026330514e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0813369026330514e-06\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.787654837010974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.787654837010974\n",
            "[LightGBM] [Warning] num_iterations is set=113, num_iteration=113 will be ignored. Current value: num_iterations=113\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1543406516103184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1543406516103184\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9815153558235846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9815153558235846\n",
            "[LightGBM] [Warning] lambda_l2 is set=5.0813369026330514e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0813369026330514e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.787654837010974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.787654837010974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1543406516103184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1543406516103184\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.920101 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 225444\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3244\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9815153558235846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9815153558235846\n",
            "[LightGBM] [Warning] lambda_l2 is set=5.0813369026330514e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0813369026330514e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.787654837010974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.787654837010974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1543406516103184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1543406516103184\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9815153558235846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9815153558235846\n",
            "[LightGBM] [Warning] lambda_l2 is set=5.0813369026330514e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0813369026330514e-06\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.787654837010974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.787654837010974\n",
            "[LightGBM] [Warning] num_iterations is set=113, num_iteration=113 will be ignored. Current value: num_iterations=113\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1543406516103184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1543406516103184\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9815153558235846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9815153558235846\n",
            "[LightGBM] [Warning] lambda_l2 is set=5.0813369026330514e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0813369026330514e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.787654837010974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.787654837010974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1543406516103184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1543406516103184\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.932646 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 224269\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3215\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9815153558235846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9815153558235846\n",
            "[LightGBM] [Warning] lambda_l2 is set=5.0813369026330514e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0813369026330514e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.787654837010974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.787654837010974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1543406516103184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1543406516103184\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9815153558235846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9815153558235846\n",
            "[LightGBM] [Warning] lambda_l2 is set=5.0813369026330514e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0813369026330514e-06\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.787654837010974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.787654837010974\n",
            "[LightGBM] [Warning] num_iterations is set=113, num_iteration=113 will be ignored. Current value: num_iterations=113\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1543406516103184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1543406516103184\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9815153558235846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9815153558235846\n",
            "[LightGBM] [Warning] lambda_l2 is set=5.0813369026330514e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0813369026330514e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.787654837010974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.787654837010974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1543406516103184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1543406516103184\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.920698 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 224264\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3214\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9815153558235846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9815153558235846\n",
            "[LightGBM] [Warning] lambda_l2 is set=5.0813369026330514e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.0813369026330514e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.787654837010974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.787654837010974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.1543406516103184, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1543406516103184\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 00:38:26,970] Trial 4 finished with value: 0.786718842478862 and parameters: {'num_leaves': 113, 'lambda_l1': 1.787654837010974, 'lambda_l2': 5.0813369026330514e-06, 'feature_fraction': 0.9815153558235846, 'bagging_fraction': 0.1543406516103184, 'bagging_freq': 6, 'min_child_samples': 37, 'class_weight': None}. Best is trial 0 with value: 0.8218578522252493.\n",
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7242426055759799, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242426055759799\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.1410151354471125e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1410151354471125e-08\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.326254436110919e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.326254436110919e-05\n",
            "[LightGBM] [Warning] num_iterations is set=140, num_iteration=140 will be ignored. Current value: num_iterations=140\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6466684467227406, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6466684467227406\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7242426055759799, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242426055759799\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.1410151354471125e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1410151354471125e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.326254436110919e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.326254436110919e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6466684467227406, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6466684467227406\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.650048 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 203890\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 2075\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7242426055759799, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242426055759799\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.1410151354471125e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1410151354471125e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.326254436110919e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.326254436110919e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6466684467227406, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6466684467227406\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7242426055759799, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242426055759799\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.1410151354471125e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1410151354471125e-08\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.326254436110919e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.326254436110919e-05\n",
            "[LightGBM] [Warning] num_iterations is set=140, num_iteration=140 will be ignored. Current value: num_iterations=140\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6466684467227406, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6466684467227406\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7242426055759799, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242426055759799\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.1410151354471125e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1410151354471125e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.326254436110919e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.326254436110919e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6466684467227406, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6466684467227406\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.512756 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 203101\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 2078\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7242426055759799, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242426055759799\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.1410151354471125e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1410151354471125e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.326254436110919e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.326254436110919e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6466684467227406, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6466684467227406\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7242426055759799, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242426055759799\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.1410151354471125e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1410151354471125e-08\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.326254436110919e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.326254436110919e-05\n",
            "[LightGBM] [Warning] num_iterations is set=140, num_iteration=140 will be ignored. Current value: num_iterations=140\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6466684467227406, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6466684467227406\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7242426055759799, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242426055759799\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.1410151354471125e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1410151354471125e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.326254436110919e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.326254436110919e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6466684467227406, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6466684467227406\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.507161 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 204504\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2099\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7242426055759799, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242426055759799\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.1410151354471125e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1410151354471125e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.326254436110919e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.326254436110919e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6466684467227406, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6466684467227406\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7242426055759799, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242426055759799\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.1410151354471125e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1410151354471125e-08\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.326254436110919e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.326254436110919e-05\n",
            "[LightGBM] [Warning] num_iterations is set=140, num_iteration=140 will be ignored. Current value: num_iterations=140\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6466684467227406, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6466684467227406\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7242426055759799, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242426055759799\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.1410151354471125e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1410151354471125e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.326254436110919e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.326254436110919e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6466684467227406, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6466684467227406\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.497660 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 203561\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2089\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7242426055759799, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242426055759799\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.1410151354471125e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1410151354471125e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.326254436110919e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.326254436110919e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6466684467227406, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6466684467227406\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7242426055759799, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242426055759799\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.1410151354471125e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1410151354471125e-08\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.326254436110919e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.326254436110919e-05\n",
            "[LightGBM] [Warning] num_iterations is set=140, num_iteration=140 will be ignored. Current value: num_iterations=140\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6466684467227406, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6466684467227406\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7242426055759799, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242426055759799\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.1410151354471125e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1410151354471125e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.326254436110919e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.326254436110919e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6466684467227406, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6466684467227406\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.520662 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 203423\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2081\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7242426055759799, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242426055759799\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.1410151354471125e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1410151354471125e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.326254436110919e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.326254436110919e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6466684467227406, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6466684467227406\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 00:41:43,147] Trial 5 finished with value: 0.7886802675396679 and parameters: {'num_leaves': 140, 'lambda_l1': 2.326254436110919e-05, 'lambda_l2': 3.1410151354471125e-08, 'feature_fraction': 0.7242426055759799, 'bagging_fraction': 0.6466684467227406, 'bagging_freq': 10, 'min_child_samples': 74, 'class_weight': None}. Best is trial 0 with value: 0.8218578522252493.\n",
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8290677011899559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8290677011899559\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.1107276345934285e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1107276345934285e-05\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.511101637891432e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.511101637891432e-08\n",
            "[LightGBM] [Warning] num_iterations is set=129, num_iteration=129 will be ignored. Current value: num_iterations=129\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.48555274227181977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48555274227181977\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8290677011899559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8290677011899559\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.1107276345934285e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1107276345934285e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.511101637891432e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.511101637891432e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.48555274227181977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48555274227181977\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.975843 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 226866\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3361\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8290677011899559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8290677011899559\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.1107276345934285e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1107276345934285e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.511101637891432e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.511101637891432e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.48555274227181977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48555274227181977\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8290677011899559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8290677011899559\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.1107276345934285e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1107276345934285e-05\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.511101637891432e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.511101637891432e-08\n",
            "[LightGBM] [Warning] num_iterations is set=129, num_iteration=129 will be ignored. Current value: num_iterations=129\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.48555274227181977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48555274227181977\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8290677011899559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8290677011899559\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.1107276345934285e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1107276345934285e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.511101637891432e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.511101637891432e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.48555274227181977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48555274227181977\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.033617 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 225597\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3345\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8290677011899559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8290677011899559\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.1107276345934285e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1107276345934285e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.511101637891432e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.511101637891432e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.48555274227181977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48555274227181977\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8290677011899559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8290677011899559\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.1107276345934285e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1107276345934285e-05\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.511101637891432e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.511101637891432e-08\n",
            "[LightGBM] [Warning] num_iterations is set=129, num_iteration=129 will be ignored. Current value: num_iterations=129\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.48555274227181977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48555274227181977\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8290677011899559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8290677011899559\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.1107276345934285e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1107276345934285e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.511101637891432e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.511101637891432e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.48555274227181977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48555274227181977\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.452981 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 227070\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3373\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8290677011899559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8290677011899559\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.1107276345934285e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1107276345934285e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.511101637891432e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.511101637891432e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.48555274227181977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48555274227181977\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8290677011899559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8290677011899559\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.1107276345934285e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1107276345934285e-05\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.511101637891432e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.511101637891432e-08\n",
            "[LightGBM] [Warning] num_iterations is set=129, num_iteration=129 will be ignored. Current value: num_iterations=129\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.48555274227181977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48555274227181977\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8290677011899559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8290677011899559\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.1107276345934285e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1107276345934285e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.511101637891432e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.511101637891432e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.48555274227181977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48555274227181977\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.983409 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 226063\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3357\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8290677011899559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8290677011899559\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.1107276345934285e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1107276345934285e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.511101637891432e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.511101637891432e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.48555274227181977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48555274227181977\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8290677011899559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8290677011899559\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.1107276345934285e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1107276345934285e-05\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.511101637891432e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.511101637891432e-08\n",
            "[LightGBM] [Warning] num_iterations is set=129, num_iteration=129 will be ignored. Current value: num_iterations=129\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.48555274227181977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48555274227181977\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8290677011899559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8290677011899559\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.1107276345934285e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1107276345934285e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.511101637891432e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.511101637891432e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.48555274227181977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48555274227181977\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.998715 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 225908\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3344\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8290677011899559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8290677011899559\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.1107276345934285e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1107276345934285e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.511101637891432e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.511101637891432e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.48555274227181977, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48555274227181977\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 00:45:54,280] Trial 6 finished with value: 0.802129727843988 and parameters: {'num_leaves': 129, 'lambda_l1': 3.511101637891432e-08, 'lambda_l2': 1.1107276345934285e-05, 'feature_fraction': 0.8290677011899559, 'bagging_fraction': 0.48555274227181977, 'bagging_freq': 9, 'min_child_samples': 33, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.8218578522252493.\n",
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8806434946338872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8806434946338872\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4083660709309013e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4083660709309013e-06\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.6732821668270596e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.6732821668270596e-08\n",
            "[LightGBM] [Warning] num_iterations is set=125, num_iteration=125 will be ignored. Current value: num_iterations=125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5419164081587379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5419164081587379\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8806434946338872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8806434946338872\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4083660709309013e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4083660709309013e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.6732821668270596e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.6732821668270596e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5419164081587379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5419164081587379\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.623039 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 211400\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 2402\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8806434946338872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8806434946338872\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4083660709309013e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4083660709309013e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.6732821668270596e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.6732821668270596e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5419164081587379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5419164081587379\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8806434946338872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8806434946338872\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4083660709309013e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4083660709309013e-06\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.6732821668270596e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.6732821668270596e-08\n",
            "[LightGBM] [Warning] num_iterations is set=125, num_iteration=125 will be ignored. Current value: num_iterations=125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5419164081587379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5419164081587379\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8806434946338872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8806434946338872\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4083660709309013e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4083660709309013e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.6732821668270596e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.6732821668270596e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5419164081587379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5419164081587379\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.622374 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 210508\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 2401\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8806434946338872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8806434946338872\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4083660709309013e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4083660709309013e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.6732821668270596e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.6732821668270596e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5419164081587379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5419164081587379\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8806434946338872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8806434946338872\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4083660709309013e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4083660709309013e-06\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.6732821668270596e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.6732821668270596e-08\n",
            "[LightGBM] [Warning] num_iterations is set=125, num_iteration=125 will be ignored. Current value: num_iterations=125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5419164081587379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5419164081587379\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8806434946338872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8806434946338872\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4083660709309013e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4083660709309013e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.6732821668270596e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.6732821668270596e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5419164081587379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5419164081587379\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.689800 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 211548\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2405\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8806434946338872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8806434946338872\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4083660709309013e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4083660709309013e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.6732821668270596e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.6732821668270596e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5419164081587379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5419164081587379\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8806434946338872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8806434946338872\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4083660709309013e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4083660709309013e-06\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.6732821668270596e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.6732821668270596e-08\n",
            "[LightGBM] [Warning] num_iterations is set=125, num_iteration=125 will be ignored. Current value: num_iterations=125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5419164081587379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5419164081587379\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8806434946338872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8806434946338872\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4083660709309013e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4083660709309013e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.6732821668270596e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.6732821668270596e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5419164081587379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5419164081587379\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.955260 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 210611\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2396\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8806434946338872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8806434946338872\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4083660709309013e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4083660709309013e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.6732821668270596e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.6732821668270596e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5419164081587379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5419164081587379\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8806434946338872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8806434946338872\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4083660709309013e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4083660709309013e-06\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.6732821668270596e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.6732821668270596e-08\n",
            "[LightGBM] [Warning] num_iterations is set=125, num_iteration=125 will be ignored. Current value: num_iterations=125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5419164081587379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5419164081587379\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8806434946338872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8806434946338872\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4083660709309013e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4083660709309013e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.6732821668270596e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.6732821668270596e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5419164081587379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5419164081587379\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.928908 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 210761\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2401\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8806434946338872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8806434946338872\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4083660709309013e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4083660709309013e-06\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.6732821668270596e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.6732821668270596e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5419164081587379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5419164081587379\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 00:49:07,167] Trial 7 finished with value: 0.7939168573323253 and parameters: {'num_leaves': 125, 'lambda_l1': 5.6732821668270596e-08, 'lambda_l2': 3.4083660709309013e-06, 'feature_fraction': 0.8806434946338872, 'bagging_fraction': 0.5419164081587379, 'bagging_freq': 8, 'min_child_samples': 60, 'class_weight': None}. Best is trial 0 with value: 0.8218578522252493.\n",
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8021405397715715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021405397715715\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.04875498037597694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04875498037597694\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] lambda_l1 is set=7.116927440141963e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.116927440141963e-06\n",
            "[LightGBM] [Warning] num_iterations is set=134, num_iteration=134 will be ignored. Current value: num_iterations=134\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7723764507252652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7723764507252652\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8021405397715715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021405397715715\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.04875498037597694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04875498037597694\n",
            "[LightGBM] [Warning] lambda_l1 is set=7.116927440141963e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.116927440141963e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7723764507252652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7723764507252652\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.635978 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 210837\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 2375\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8021405397715715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021405397715715\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.04875498037597694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04875498037597694\n",
            "[LightGBM] [Warning] lambda_l1 is set=7.116927440141963e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.116927440141963e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7723764507252652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7723764507252652\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8021405397715715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021405397715715\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.04875498037597694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04875498037597694\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] lambda_l1 is set=7.116927440141963e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.116927440141963e-06\n",
            "[LightGBM] [Warning] num_iterations is set=134, num_iteration=134 will be ignored. Current value: num_iterations=134\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7723764507252652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7723764507252652\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8021405397715715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021405397715715\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.04875498037597694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04875498037597694\n",
            "[LightGBM] [Warning] lambda_l1 is set=7.116927440141963e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.116927440141963e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7723764507252652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7723764507252652\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.607541 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 209944\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 2374\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8021405397715715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021405397715715\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.04875498037597694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04875498037597694\n",
            "[LightGBM] [Warning] lambda_l1 is set=7.116927440141963e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.116927440141963e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7723764507252652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7723764507252652\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8021405397715715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021405397715715\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.04875498037597694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04875498037597694\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] lambda_l1 is set=7.116927440141963e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.116927440141963e-06\n",
            "[LightGBM] [Warning] num_iterations is set=134, num_iteration=134 will be ignored. Current value: num_iterations=134\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7723764507252652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7723764507252652\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8021405397715715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021405397715715\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.04875498037597694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04875498037597694\n",
            "[LightGBM] [Warning] lambda_l1 is set=7.116927440141963e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.116927440141963e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7723764507252652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7723764507252652\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.588125 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 211111\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2384\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8021405397715715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021405397715715\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.04875498037597694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04875498037597694\n",
            "[LightGBM] [Warning] lambda_l1 is set=7.116927440141963e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.116927440141963e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7723764507252652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7723764507252652\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8021405397715715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021405397715715\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.04875498037597694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04875498037597694\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] lambda_l1 is set=7.116927440141963e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.116927440141963e-06\n",
            "[LightGBM] [Warning] num_iterations is set=134, num_iteration=134 will be ignored. Current value: num_iterations=134\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7723764507252652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7723764507252652\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8021405397715715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021405397715715\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.04875498037597694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04875498037597694\n",
            "[LightGBM] [Warning] lambda_l1 is set=7.116927440141963e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.116927440141963e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7723764507252652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7723764507252652\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.635248 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 210236\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2378\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8021405397715715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021405397715715\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.04875498037597694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04875498037597694\n",
            "[LightGBM] [Warning] lambda_l1 is set=7.116927440141963e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.116927440141963e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7723764507252652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7723764507252652\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8021405397715715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021405397715715\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.04875498037597694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04875498037597694\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] lambda_l1 is set=7.116927440141963e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.116927440141963e-06\n",
            "[LightGBM] [Warning] num_iterations is set=134, num_iteration=134 will be ignored. Current value: num_iterations=134\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7723764507252652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7723764507252652\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8021405397715715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021405397715715\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.04875498037597694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04875498037597694\n",
            "[LightGBM] [Warning] lambda_l1 is set=7.116927440141963e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.116927440141963e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7723764507252652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7723764507252652\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.608519 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 210325\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2380\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8021405397715715, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8021405397715715\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.04875498037597694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04875498037597694\n",
            "[LightGBM] [Warning] lambda_l1 is set=7.116927440141963e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.116927440141963e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7723764507252652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7723764507252652\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 00:53:15,161] Trial 8 finished with value: 0.800895696200333 and parameters: {'num_leaves': 134, 'lambda_l1': 7.116927440141963e-06, 'lambda_l2': 0.04875498037597694, 'feature_fraction': 0.8021405397715715, 'bagging_fraction': 0.7723764507252652, 'bagging_freq': 7, 'min_child_samples': 61, 'class_weight': None}. Best is trial 0 with value: 0.8218578522252493.\n",
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.554895297513024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554895297513024\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.083650788856549e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.083650788856549e-08\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3250133246098369, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3250133246098369\n",
            "[LightGBM] [Warning] num_iterations is set=79, num_iteration=79 will be ignored. Current value: num_iterations=79\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6707843335969422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707843335969422\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] feature_fraction is set=0.554895297513024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554895297513024\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.083650788856549e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.083650788856549e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3250133246098369, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3250133246098369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6707843335969422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707843335969422\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.513151 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 207112\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 2207\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] feature_fraction is set=0.554895297513024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554895297513024\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.083650788856549e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.083650788856549e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3250133246098369, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3250133246098369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6707843335969422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707843335969422\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.554895297513024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554895297513024\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.083650788856549e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.083650788856549e-08\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3250133246098369, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3250133246098369\n",
            "[LightGBM] [Warning] num_iterations is set=79, num_iteration=79 will be ignored. Current value: num_iterations=79\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6707843335969422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707843335969422\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] feature_fraction is set=0.554895297513024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554895297513024\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.083650788856549e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.083650788856549e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3250133246098369, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3250133246098369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6707843335969422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707843335969422\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.526780 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 206002\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 2197\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] feature_fraction is set=0.554895297513024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554895297513024\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.083650788856549e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.083650788856549e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3250133246098369, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3250133246098369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6707843335969422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707843335969422\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.554895297513024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554895297513024\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.083650788856549e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.083650788856549e-08\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3250133246098369, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3250133246098369\n",
            "[LightGBM] [Warning] num_iterations is set=79, num_iteration=79 will be ignored. Current value: num_iterations=79\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6707843335969422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707843335969422\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] feature_fraction is set=0.554895297513024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554895297513024\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.083650788856549e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.083650788856549e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3250133246098369, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3250133246098369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6707843335969422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707843335969422\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.561003 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 207639\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2228\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] feature_fraction is set=0.554895297513024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554895297513024\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.083650788856549e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.083650788856549e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3250133246098369, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3250133246098369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6707843335969422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707843335969422\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.554895297513024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554895297513024\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.083650788856549e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.083650788856549e-08\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3250133246098369, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3250133246098369\n",
            "[LightGBM] [Warning] num_iterations is set=79, num_iteration=79 will be ignored. Current value: num_iterations=79\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6707843335969422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707843335969422\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] feature_fraction is set=0.554895297513024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554895297513024\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.083650788856549e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.083650788856549e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3250133246098369, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3250133246098369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6707843335969422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707843335969422\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.521022 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 206237\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2199\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] feature_fraction is set=0.554895297513024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554895297513024\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.083650788856549e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.083650788856549e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3250133246098369, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3250133246098369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6707843335969422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707843335969422\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.554895297513024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554895297513024\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.083650788856549e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.083650788856549e-08\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3250133246098369, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3250133246098369\n",
            "[LightGBM] [Warning] num_iterations is set=79, num_iteration=79 will be ignored. Current value: num_iterations=79\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6707843335969422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707843335969422\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] feature_fraction is set=0.554895297513024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554895297513024\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.083650788856549e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.083650788856549e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3250133246098369, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3250133246098369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6707843335969422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707843335969422\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.515201 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 206561\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 2210\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 00:54:38,893] Trial 9 finished with value: 0.8224156711912685 and parameters: {'num_leaves': 79, 'lambda_l1': 0.3250133246098369, 'lambda_l2': 1.083650788856549e-08, 'feature_fraction': 0.554895297513024, 'bagging_fraction': 0.6707843335969422, 'bagging_freq': 7, 'min_child_samples': 68, 'class_weight': None}. Best is trial 9 with value: 0.8224156711912685.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=68, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68\n",
            "[LightGBM] [Warning] feature_fraction is set=0.554895297513024, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.554895297513024\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.083650788856549e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.083650788856549e-08\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3250133246098369, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3250133246098369\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6707843335969422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6707843335969422\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4300324396095686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4300324396095686\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0005384409534462252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005384409534462252\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.007780269014614097, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007780269014614097\n",
            "[LightGBM] [Warning] num_iterations is set=70, num_iteration=70 will be ignored. Current value: num_iterations=70\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9843993659784831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9843993659784831\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4300324396095686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4300324396095686\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0005384409534462252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005384409534462252\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.007780269014614097, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007780269014614097\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9843993659784831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9843993659784831\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.411086 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 193983\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 1735\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4300324396095686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4300324396095686\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0005384409534462252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005384409534462252\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.007780269014614097, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007780269014614097\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9843993659784831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9843993659784831\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4300324396095686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4300324396095686\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0005384409534462252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005384409534462252\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.007780269014614097, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007780269014614097\n",
            "[LightGBM] [Warning] num_iterations is set=70, num_iteration=70 will be ignored. Current value: num_iterations=70\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9843993659784831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9843993659784831\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4300324396095686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4300324396095686\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0005384409534462252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005384409534462252\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.007780269014614097, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007780269014614097\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9843993659784831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9843993659784831\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.412700 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 192929\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 1728\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4300324396095686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4300324396095686\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0005384409534462252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005384409534462252\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.007780269014614097, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007780269014614097\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9843993659784831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9843993659784831\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4300324396095686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4300324396095686\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0005384409534462252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005384409534462252\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.007780269014614097, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007780269014614097\n",
            "[LightGBM] [Warning] num_iterations is set=70, num_iteration=70 will be ignored. Current value: num_iterations=70\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9843993659784831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9843993659784831\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4300324396095686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4300324396095686\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0005384409534462252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005384409534462252\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.007780269014614097, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007780269014614097\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9843993659784831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9843993659784831\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.422313 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 194136\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 1740\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4300324396095686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4300324396095686\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0005384409534462252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005384409534462252\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.007780269014614097, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007780269014614097\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9843993659784831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9843993659784831\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4300324396095686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4300324396095686\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0005384409534462252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005384409534462252\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.007780269014614097, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007780269014614097\n",
            "[LightGBM] [Warning] num_iterations is set=70, num_iteration=70 will be ignored. Current value: num_iterations=70\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9843993659784831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9843993659784831\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4300324396095686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4300324396095686\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0005384409534462252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005384409534462252\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.007780269014614097, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007780269014614097\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9843993659784831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9843993659784831\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.388505 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 193086\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 1727\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4300324396095686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4300324396095686\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0005384409534462252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005384409534462252\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.007780269014614097, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007780269014614097\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9843993659784831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9843993659784831\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4300324396095686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4300324396095686\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0005384409534462252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005384409534462252\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.007780269014614097, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007780269014614097\n",
            "[LightGBM] [Warning] num_iterations is set=70, num_iteration=70 will be ignored. Current value: num_iterations=70\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9843993659784831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9843993659784831\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4300324396095686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4300324396095686\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0005384409534462252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005384409534462252\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.007780269014614097, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007780269014614097\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9843993659784831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9843993659784831\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.413307 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 192757\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 1715\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 00:55:42,560] Trial 10 finished with value: 0.8283651941254406 and parameters: {'num_leaves': 70, 'lambda_l1': 0.007780269014614097, 'lambda_l2': 0.0005384409534462252, 'feature_fraction': 0.4300324396095686, 'bagging_fraction': 0.9843993659784831, 'bagging_freq': 4, 'min_child_samples': 99, 'class_weight': None}. Best is trial 10 with value: 0.8283651941254406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4300324396095686, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4300324396095686\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0005384409534462252, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005384409534462252\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.007780269014614097, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.007780269014614097\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9843993659784831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9843993659784831\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35442874911685107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35442874911685107\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.9961041040555307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9961041040555307\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0090672937534877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0090672937534877\n",
            "[LightGBM] [Warning] num_iterations is set=70, num_iteration=70 will be ignored. Current value: num_iterations=70\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9994319236457065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994319236457065\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35442874911685107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35442874911685107\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.9961041040555307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9961041040555307\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0090672937534877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0090672937534877\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9994319236457065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994319236457065\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.438441 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 197466\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 1844\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35442874911685107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35442874911685107\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.9961041040555307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9961041040555307\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0090672937534877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0090672937534877\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9994319236457065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994319236457065\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35442874911685107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35442874911685107\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.9961041040555307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9961041040555307\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0090672937534877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0090672937534877\n",
            "[LightGBM] [Warning] num_iterations is set=70, num_iteration=70 will be ignored. Current value: num_iterations=70\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9994319236457065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994319236457065\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35442874911685107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35442874911685107\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.9961041040555307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9961041040555307\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0090672937534877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0090672937534877\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9994319236457065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994319236457065\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.416473 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 196346\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 1835\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35442874911685107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35442874911685107\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.9961041040555307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9961041040555307\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0090672937534877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0090672937534877\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9994319236457065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994319236457065\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35442874911685107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35442874911685107\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.9961041040555307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9961041040555307\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0090672937534877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0090672937534877\n",
            "[LightGBM] [Warning] num_iterations is set=70, num_iteration=70 will be ignored. Current value: num_iterations=70\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9994319236457065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994319236457065\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35442874911685107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35442874911685107\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.9961041040555307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9961041040555307\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0090672937534877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0090672937534877\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9994319236457065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994319236457065\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.414815 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 197078\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 1832\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35442874911685107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35442874911685107\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.9961041040555307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9961041040555307\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0090672937534877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0090672937534877\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9994319236457065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994319236457065\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35442874911685107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35442874911685107\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.9961041040555307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9961041040555307\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0090672937534877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0090672937534877\n",
            "[LightGBM] [Warning] num_iterations is set=70, num_iteration=70 will be ignored. Current value: num_iterations=70\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9994319236457065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994319236457065\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35442874911685107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35442874911685107\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.9961041040555307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9961041040555307\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0090672937534877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0090672937534877\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9994319236457065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994319236457065\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.472809 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 196197\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 1824\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35442874911685107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35442874911685107\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.9961041040555307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9961041040555307\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0090672937534877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0090672937534877\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9994319236457065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994319236457065\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35442874911685107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35442874911685107\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.9961041040555307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9961041040555307\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0090672937534877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0090672937534877\n",
            "[LightGBM] [Warning] num_iterations is set=70, num_iteration=70 will be ignored. Current value: num_iterations=70\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9994319236457065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994319236457065\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35442874911685107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35442874911685107\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.9961041040555307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9961041040555307\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0090672937534877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0090672937534877\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9994319236457065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994319236457065\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.772782 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 196473\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 1831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 00:56:41,638] Trial 11 finished with value: 0.8300715644320492 and parameters: {'num_leaves': 70, 'lambda_l1': 0.0090672937534877, 'lambda_l2': 2.9961041040555307, 'feature_fraction': 0.35442874911685107, 'bagging_fraction': 0.9994319236457065, 'bagging_freq': 4, 'min_child_samples': 90, 'class_weight': None}. Best is trial 11 with value: 0.8300715644320492.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=90, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=90\n",
            "[LightGBM] [Warning] feature_fraction is set=0.35442874911685107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.35442874911685107\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.9961041040555307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9961041040555307\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0090672937534877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0090672937534877\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9994319236457065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994319236457065\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.2964482908550868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2964482908550868\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0424198271779863, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0424198271779863\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004141154420028898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004141154420028898\n",
            "[LightGBM] [Warning] num_iterations is set=70, num_iteration=70 will be ignored. Current value: num_iterations=70\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9281769807093476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9281769807093476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] feature_fraction is set=0.2964482908550868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2964482908550868\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0424198271779863, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0424198271779863\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004141154420028898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004141154420028898\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9281769807093476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9281769807093476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.478342 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 193512\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 1721\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] feature_fraction is set=0.2964482908550868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2964482908550868\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0424198271779863, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0424198271779863\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004141154420028898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004141154420028898\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9281769807093476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9281769807093476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.2964482908550868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2964482908550868\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0424198271779863, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0424198271779863\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004141154420028898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004141154420028898\n",
            "[LightGBM] [Warning] num_iterations is set=70, num_iteration=70 will be ignored. Current value: num_iterations=70\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9281769807093476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9281769807093476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] feature_fraction is set=0.2964482908550868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2964482908550868\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0424198271779863, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0424198271779863\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004141154420028898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004141154420028898\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9281769807093476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9281769807093476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.394066 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 192626\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 1719\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] feature_fraction is set=0.2964482908550868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2964482908550868\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0424198271779863, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0424198271779863\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004141154420028898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004141154420028898\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9281769807093476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9281769807093476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.2964482908550868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2964482908550868\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0424198271779863, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0424198271779863\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004141154420028898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004141154420028898\n",
            "[LightGBM] [Warning] num_iterations is set=70, num_iteration=70 will be ignored. Current value: num_iterations=70\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9281769807093476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9281769807093476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] feature_fraction is set=0.2964482908550868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2964482908550868\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0424198271779863, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0424198271779863\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004141154420028898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004141154420028898\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9281769807093476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9281769807093476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.415417 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 193732\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 1728\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] feature_fraction is set=0.2964482908550868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2964482908550868\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0424198271779863, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0424198271779863\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004141154420028898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004141154420028898\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9281769807093476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9281769807093476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.2964482908550868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2964482908550868\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0424198271779863, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0424198271779863\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004141154420028898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004141154420028898\n",
            "[LightGBM] [Warning] num_iterations is set=70, num_iteration=70 will be ignored. Current value: num_iterations=70\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9281769807093476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9281769807093476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] feature_fraction is set=0.2964482908550868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2964482908550868\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0424198271779863, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0424198271779863\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004141154420028898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004141154420028898\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9281769807093476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9281769807093476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.410695 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 192750\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 1717\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] feature_fraction is set=0.2964482908550868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2964482908550868\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0424198271779863, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0424198271779863\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004141154420028898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004141154420028898\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9281769807093476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9281769807093476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.2964482908550868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2964482908550868\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0424198271779863, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0424198271779863\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004141154420028898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004141154420028898\n",
            "[LightGBM] [Warning] num_iterations is set=70, num_iteration=70 will be ignored. Current value: num_iterations=70\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9281769807093476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9281769807093476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] feature_fraction is set=0.2964482908550868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2964482908550868\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0424198271779863, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0424198271779863\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004141154420028898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004141154420028898\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9281769807093476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9281769807093476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.509933 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 192520\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 1708\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 00:57:34,654] Trial 12 finished with value: 0.822340860057922 and parameters: {'num_leaves': 70, 'lambda_l1': 0.004141154420028898, 'lambda_l2': 2.0424198271779863, 'feature_fraction': 0.2964482908550868, 'bagging_fraction': 0.9281769807093476, 'bagging_freq': 3, 'min_child_samples': 100, 'class_weight': None}. Best is trial 11 with value: 0.8300715644320492.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
            "[LightGBM] [Warning] feature_fraction is set=0.2964482908550868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2964482908550868\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0424198271779863, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0424198271779863\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004141154420028898, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004141154420028898\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9281769807093476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9281769807093476\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4082765767030636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4082765767030636\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.0370737204962084, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0370737204962084\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0029897933016757353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0029897933016757353\n",
            "[LightGBM] [Warning] num_iterations is set=94, num_iteration=94 will be ignored. Current value: num_iterations=94\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9808954337017248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9808954337017248\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4082765767030636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4082765767030636\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.0370737204962084, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0370737204962084\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0029897933016757353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0029897933016757353\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9808954337017248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9808954337017248\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.388144 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 193983\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 1735\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4082765767030636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4082765767030636\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.0370737204962084, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0370737204962084\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0029897933016757353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0029897933016757353\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9808954337017248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9808954337017248\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.4082765767030636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4082765767030636\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.0370737204962084, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0370737204962084\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0029897933016757353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0029897933016757353\n",
            "[LightGBM] [Warning] num_iterations is set=94, num_iteration=94 will be ignored. Current value: num_iterations=94\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9808954337017248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9808954337017248\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4082765767030636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4082765767030636\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.0370737204962084, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0370737204962084\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0029897933016757353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0029897933016757353\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9808954337017248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9808954337017248\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.621241 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 192929\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 1728\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4082765767030636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4082765767030636\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.0370737204962084, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0370737204962084\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0029897933016757353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0029897933016757353\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9808954337017248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9808954337017248\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4082765767030636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4082765767030636\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.0370737204962084, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0370737204962084\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0029897933016757353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0029897933016757353\n",
            "[LightGBM] [Warning] num_iterations is set=94, num_iteration=94 will be ignored. Current value: num_iterations=94\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9808954337017248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9808954337017248\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4082765767030636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4082765767030636\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.0370737204962084, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0370737204962084\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0029897933016757353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0029897933016757353\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9808954337017248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9808954337017248\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.637214 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 194136\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 1740\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4082765767030636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4082765767030636\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.0370737204962084, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0370737204962084\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0029897933016757353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0029897933016757353\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9808954337017248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9808954337017248\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4082765767030636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4082765767030636\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.0370737204962084, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0370737204962084\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0029897933016757353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0029897933016757353\n",
            "[LightGBM] [Warning] num_iterations is set=94, num_iteration=94 will be ignored. Current value: num_iterations=94\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9808954337017248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9808954337017248\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4082765767030636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4082765767030636\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.0370737204962084, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0370737204962084\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0029897933016757353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0029897933016757353\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9808954337017248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9808954337017248\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.397472 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 193086\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 1727\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4082765767030636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4082765767030636\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.0370737204962084, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0370737204962084\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0029897933016757353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0029897933016757353\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9808954337017248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9808954337017248\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4082765767030636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4082765767030636\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.0370737204962084, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0370737204962084\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0029897933016757353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0029897933016757353\n",
            "[LightGBM] [Warning] num_iterations is set=94, num_iteration=94 will be ignored. Current value: num_iterations=94\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9808954337017248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9808954337017248\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4082765767030636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4082765767030636\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.0370737204962084, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0370737204962084\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0029897933016757353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0029897933016757353\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9808954337017248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9808954337017248\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.390922 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 192757\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 1715\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
            "[LightGBM] [Warning] feature_fraction is set=0.4082765767030636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4082765767030636\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.0370737204962084, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0370737204962084\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0029897933016757353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0029897933016757353\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9808954337017248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9808954337017248\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 00:59:11,947] Trial 13 finished with value: 0.8203964654494149 and parameters: {'num_leaves': 94, 'lambda_l1': 0.0029897933016757353, 'lambda_l2': 3.0370737204962084, 'feature_fraction': 0.4082765767030636, 'bagging_fraction': 0.9808954337017248, 'bagging_freq': 4, 'min_child_samples': 99, 'class_weight': None}. Best is trial 11 with value: 0.8300715644320492.\n",
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.46589064636055044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46589064636055044\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00040951897384737437, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00040951897384737437\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005935002676470299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005935002676470299\n",
            "[LightGBM] [Warning] num_iterations is set=101, num_iteration=101 will be ignored. Current value: num_iterations=101\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8245929157155876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8245929157155876\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.46589064636055044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46589064636055044\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00040951897384737437, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00040951897384737437\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005935002676470299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005935002676470299\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8245929157155876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8245929157155876\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.018548 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 228248\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3498\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.46589064636055044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46589064636055044\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00040951897384737437, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00040951897384737437\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005935002676470299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005935002676470299\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8245929157155876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8245929157155876\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.46589064636055044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46589064636055044\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00040951897384737437, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00040951897384737437\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005935002676470299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005935002676470299\n",
            "[LightGBM] [Warning] num_iterations is set=101, num_iteration=101 will be ignored. Current value: num_iterations=101\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8245929157155876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8245929157155876\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.46589064636055044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46589064636055044\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00040951897384737437, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00040951897384737437\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005935002676470299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005935002676470299\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8245929157155876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8245929157155876\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.950553 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 227132\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3498\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.46589064636055044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46589064636055044\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00040951897384737437, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00040951897384737437\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005935002676470299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005935002676470299\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8245929157155876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8245929157155876\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.46589064636055044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46589064636055044\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00040951897384737437, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00040951897384737437\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005935002676470299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005935002676470299\n",
            "[LightGBM] [Warning] num_iterations is set=101, num_iteration=101 will be ignored. Current value: num_iterations=101\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8245929157155876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8245929157155876\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.46589064636055044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46589064636055044\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00040951897384737437, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00040951897384737437\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005935002676470299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005935002676470299\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8245929157155876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8245929157155876\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.967220 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 228312\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3498\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.46589064636055044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46589064636055044\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00040951897384737437, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00040951897384737437\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005935002676470299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005935002676470299\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8245929157155876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8245929157155876\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.46589064636055044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46589064636055044\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00040951897384737437, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00040951897384737437\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005935002676470299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005935002676470299\n",
            "[LightGBM] [Warning] num_iterations is set=101, num_iteration=101 will be ignored. Current value: num_iterations=101\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8245929157155876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8245929157155876\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.46589064636055044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46589064636055044\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00040951897384737437, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00040951897384737437\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005935002676470299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005935002676470299\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8245929157155876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8245929157155876\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.374860 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 227485\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3498\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.46589064636055044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46589064636055044\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00040951897384737437, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00040951897384737437\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005935002676470299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005935002676470299\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8245929157155876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8245929157155876\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.46589064636055044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46589064636055044\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00040951897384737437, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00040951897384737437\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005935002676470299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005935002676470299\n",
            "[LightGBM] [Warning] num_iterations is set=101, num_iteration=101 will be ignored. Current value: num_iterations=101\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8245929157155876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8245929157155876\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.46589064636055044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46589064636055044\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00040951897384737437, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00040951897384737437\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005935002676470299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005935002676470299\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8245929157155876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8245929157155876\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.915883 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 227467\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3498\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 01:01:41,162] Trial 14 finished with value: 0.8382665127034429 and parameters: {'num_leaves': 101, 'lambda_l1': 0.0005935002676470299, 'lambda_l2': 0.00040951897384737437, 'feature_fraction': 0.46589064636055044, 'bagging_fraction': 0.8245929157155876, 'bagging_freq': 0, 'min_child_samples': 5, 'class_weight': None}. Best is trial 14 with value: 0.8382665127034429.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.46589064636055044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46589064636055044\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00040951897384737437, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00040951897384737437\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005935002676470299, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005935002676470299\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8245929157155876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8245929157155876\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6059214861030116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6059214861030116\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03823918021085263, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03823918021085263\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023713179464305553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023713179464305553\n",
            "[LightGBM] [Warning] num_iterations is set=98, num_iteration=98 will be ignored. Current value: num_iterations=98\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.811383056854317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.811383056854317\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6059214861030116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6059214861030116\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03823918021085263, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03823918021085263\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023713179464305553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023713179464305553\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.811383056854317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.811383056854317\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.926310 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 228248\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3498\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6059214861030116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6059214861030116\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03823918021085263, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03823918021085263\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023713179464305553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023713179464305553\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.811383056854317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.811383056854317\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6059214861030116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6059214861030116\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03823918021085263, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03823918021085263\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023713179464305553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023713179464305553\n",
            "[LightGBM] [Warning] num_iterations is set=98, num_iteration=98 will be ignored. Current value: num_iterations=98\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.811383056854317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.811383056854317\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6059214861030116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6059214861030116\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03823918021085263, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03823918021085263\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023713179464305553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023713179464305553\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.811383056854317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.811383056854317\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.983387 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 227132\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3498\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6059214861030116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6059214861030116\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03823918021085263, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03823918021085263\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023713179464305553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023713179464305553\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.811383056854317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.811383056854317\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6059214861030116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6059214861030116\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03823918021085263, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03823918021085263\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023713179464305553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023713179464305553\n",
            "[LightGBM] [Warning] num_iterations is set=98, num_iteration=98 will be ignored. Current value: num_iterations=98\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.811383056854317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.811383056854317\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6059214861030116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6059214861030116\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03823918021085263, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03823918021085263\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023713179464305553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023713179464305553\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.811383056854317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.811383056854317\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.999924 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 228312\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3498\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6059214861030116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6059214861030116\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03823918021085263, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03823918021085263\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023713179464305553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023713179464305553\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.811383056854317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.811383056854317\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6059214861030116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6059214861030116\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03823918021085263, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03823918021085263\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023713179464305553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023713179464305553\n",
            "[LightGBM] [Warning] num_iterations is set=98, num_iteration=98 will be ignored. Current value: num_iterations=98\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.811383056854317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.811383056854317\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6059214861030116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6059214861030116\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03823918021085263, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03823918021085263\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023713179464305553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023713179464305553\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.811383056854317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.811383056854317\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.940461 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 227485\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3498\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6059214861030116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6059214861030116\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03823918021085263, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03823918021085263\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023713179464305553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023713179464305553\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.811383056854317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.811383056854317\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6059214861030116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6059214861030116\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03823918021085263, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03823918021085263\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023713179464305553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023713179464305553\n",
            "[LightGBM] [Warning] num_iterations is set=98, num_iteration=98 will be ignored. Current value: num_iterations=98\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.811383056854317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.811383056854317\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6059214861030116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6059214861030116\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03823918021085263, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03823918021085263\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023713179464305553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023713179464305553\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.811383056854317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.811383056854317\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.958322 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 227467\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3498\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 01:04:12,840] Trial 15 finished with value: 0.838421838163188 and parameters: {'num_leaves': 98, 'lambda_l1': 0.00023713179464305553, 'lambda_l2': 0.03823918021085263, 'feature_fraction': 0.6059214861030116, 'bagging_fraction': 0.811383056854317, 'bagging_freq': 0, 'min_child_samples': 4, 'class_weight': None}. Best is trial 15 with value: 0.838421838163188.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6059214861030116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6059214861030116\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03823918021085263, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03823918021085263\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023713179464305553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023713179464305553\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.811383056854317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.811383056854317\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6042844684544197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6042844684544197\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015446064705094659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015446064705094659\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.000303314864553927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000303314864553927\n",
            "[LightGBM] [Warning] num_iterations is set=100, num_iteration=100 will be ignored. Current value: num_iterations=100\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7662473806058628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7662473806058628\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6042844684544197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6042844684544197\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015446064705094659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015446064705094659\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.000303314864553927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000303314864553927\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7662473806058628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7662473806058628\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.962238 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 228252\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3500\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6042844684544197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6042844684544197\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015446064705094659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015446064705094659\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.000303314864553927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000303314864553927\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7662473806058628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7662473806058628\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6042844684544197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6042844684544197\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015446064705094659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015446064705094659\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.000303314864553927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000303314864553927\n",
            "[LightGBM] [Warning] num_iterations is set=100, num_iteration=100 will be ignored. Current value: num_iterations=100\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7662473806058628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7662473806058628\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6042844684544197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6042844684544197\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015446064705094659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015446064705094659\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.000303314864553927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000303314864553927\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7662473806058628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7662473806058628\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.962001 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 227136\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3500\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6042844684544197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6042844684544197\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015446064705094659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015446064705094659\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.000303314864553927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000303314864553927\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7662473806058628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7662473806058628\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6042844684544197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6042844684544197\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015446064705094659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015446064705094659\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.000303314864553927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000303314864553927\n",
            "[LightGBM] [Warning] num_iterations is set=100, num_iteration=100 will be ignored. Current value: num_iterations=100\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7662473806058628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7662473806058628\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6042844684544197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6042844684544197\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015446064705094659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015446064705094659\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.000303314864553927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000303314864553927\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7662473806058628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7662473806058628\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.419421 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 228314\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3499\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6042844684544197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6042844684544197\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015446064705094659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015446064705094659\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.000303314864553927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000303314864553927\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7662473806058628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7662473806058628\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6042844684544197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6042844684544197\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015446064705094659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015446064705094659\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.000303314864553927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000303314864553927\n",
            "[LightGBM] [Warning] num_iterations is set=100, num_iteration=100 will be ignored. Current value: num_iterations=100\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7662473806058628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7662473806058628\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6042844684544197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6042844684544197\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015446064705094659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015446064705094659\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.000303314864553927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000303314864553927\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7662473806058628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7662473806058628\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.933422 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 227489\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3500\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6042844684544197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6042844684544197\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015446064705094659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015446064705094659\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.000303314864553927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000303314864553927\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7662473806058628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7662473806058628\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6042844684544197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6042844684544197\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015446064705094659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015446064705094659\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.000303314864553927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000303314864553927\n",
            "[LightGBM] [Warning] num_iterations is set=100, num_iteration=100 will be ignored. Current value: num_iterations=100\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7662473806058628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7662473806058628\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6042844684544197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6042844684544197\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015446064705094659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015446064705094659\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.000303314864553927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000303314864553927\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7662473806058628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7662473806058628\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.953274 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 227471\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3500\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 01:07:20,862] Trial 16 finished with value: 0.8372151065057839 and parameters: {'num_leaves': 100, 'lambda_l1': 0.000303314864553927, 'lambda_l2': 0.015446064705094659, 'feature_fraction': 0.6042844684544197, 'bagging_fraction': 0.7662473806058628, 'bagging_freq': 0, 'min_child_samples': 1, 'class_weight': None}. Best is trial 15 with value: 0.838421838163188.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6042844684544197, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6042844684544197\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015446064705094659, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015446064705094659\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.000303314864553927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.000303314864553927\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7662473806058628, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7662473806058628\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6797365181489236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6797365181489236\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.473299603643343e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.473299603643343e-05\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6894640621933276e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6894640621933276e-06\n",
            "[LightGBM] [Warning] num_iterations is set=103, num_iteration=103 will be ignored. Current value: num_iterations=103\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8137828473304445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8137828473304445\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6797365181489236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6797365181489236\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.473299603643343e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.473299603643343e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6894640621933276e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6894640621933276e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8137828473304445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8137828473304445\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.367185 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 228252\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3500\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6797365181489236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6797365181489236\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.473299603643343e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.473299603643343e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6894640621933276e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6894640621933276e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8137828473304445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8137828473304445\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6797365181489236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6797365181489236\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.473299603643343e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.473299603643343e-05\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6894640621933276e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6894640621933276e-06\n",
            "[LightGBM] [Warning] num_iterations is set=103, num_iteration=103 will be ignored. Current value: num_iterations=103\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8137828473304445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8137828473304445\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6797365181489236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6797365181489236\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.473299603643343e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.473299603643343e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6894640621933276e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6894640621933276e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8137828473304445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8137828473304445\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.537939 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 227136\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3500\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421748 -> initscore=-0.315601\n",
            "[LightGBM] [Info] Start training from score -0.315601\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6797365181489236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6797365181489236\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.473299603643343e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.473299603643343e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6894640621933276e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6894640621933276e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8137828473304445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8137828473304445\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6797365181489236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6797365181489236\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.473299603643343e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.473299603643343e-05\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6894640621933276e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6894640621933276e-06\n",
            "[LightGBM] [Warning] num_iterations is set=103, num_iteration=103 will be ignored. Current value: num_iterations=103\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8137828473304445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8137828473304445\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6797365181489236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6797365181489236\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.473299603643343e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.473299603643343e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6894640621933276e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6894640621933276e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8137828473304445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8137828473304445\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.272727 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 228314\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3499\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6797365181489236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6797365181489236\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.473299603643343e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.473299603643343e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6894640621933276e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6894640621933276e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8137828473304445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8137828473304445\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6797365181489236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6797365181489236\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.473299603643343e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.473299603643343e-05\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6894640621933276e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6894640621933276e-06\n",
            "[LightGBM] [Warning] num_iterations is set=103, num_iteration=103 will be ignored. Current value: num_iterations=103\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8137828473304445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8137828473304445\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6797365181489236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6797365181489236\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.473299603643343e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.473299603643343e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6894640621933276e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6894640621933276e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8137828473304445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8137828473304445\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.972268 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 227489\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3500\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6797365181489236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6797365181489236\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.473299603643343e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.473299603643343e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6894640621933276e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6894640621933276e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8137828473304445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8137828473304445\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6797365181489236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6797365181489236\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.473299603643343e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.473299603643343e-05\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6894640621933276e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6894640621933276e-06\n",
            "[LightGBM] [Warning] num_iterations is set=103, num_iteration=103 will be ignored. Current value: num_iterations=103\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8137828473304445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8137828473304445\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6797365181489236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6797365181489236\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.473299603643343e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.473299603643343e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6894640621933276e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6894640621933276e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8137828473304445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8137828473304445\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.985510 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 227471\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3500\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421763 -> initscore=-0.315541\n",
            "[LightGBM] [Info] Start training from score -0.315541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 01:10:55,223] Trial 17 finished with value: 0.8301237505922799 and parameters: {'num_leaves': 103, 'lambda_l1': 1.6894640621933276e-06, 'lambda_l2': 8.473299603643343e-05, 'feature_fraction': 0.6797365181489236, 'bagging_fraction': 0.8137828473304445, 'bagging_freq': 1, 'min_child_samples': 1, 'class_weight': None}. Best is trial 15 with value: 0.838421838163188.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6797365181489236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6797365181489236\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.473299603643343e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.473299603643343e-05\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6894640621933276e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6894640621933276e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8137828473304445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8137828473304445\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] num_iterations is set=90, num_iteration=90 will be ignored. Current value: num_iterations=90\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.015250 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 228218\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3492\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] num_iterations is set=90, num_iteration=90 will be ignored. Current value: num_iterations=90\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.943195 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 227084\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3489\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] num_iterations is set=90, num_iteration=90 will be ignored. Current value: num_iterations=90\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.958555 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 228288\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3493\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] num_iterations is set=90, num_iteration=90 will be ignored. Current value: num_iterations=90\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.022700 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 227453\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3492\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] num_iterations is set=90, num_iteration=90 will be ignored. Current value: num_iterations=90\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.995322 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 227442\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3493\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 01:13:02,874] Trial 18 finished with value: 0.8435378558379825 and parameters: {'num_leaves': 90, 'lambda_l1': 0.0004388081618673077, 'lambda_l2': 0.004050094092094895, 'feature_fraction': 0.48991173557781453, 'bagging_fraction': 0.4037551307865023, 'bagging_freq': 0, 'min_child_samples': 15, 'class_weight': 'balanced'}. Best is trial 18 with value: 0.8435378558379825.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-a40d882ac625>:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 5.0),\n",
            "<ipython-input-46-a40d882ac625>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 5.0),\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/trial/_trial.py:676: RuntimeWarning: Inconsistent parameter values for distribution with name \"num_leaves\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 70, 'high': 150}\n",
            "  warnings.warn(\n",
            "<ipython-input-46-a40d882ac625>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
            "<ipython-input-46-a40d882ac625>:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.25147880251501853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25147880251501853\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.30925898116807393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30925898116807393\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0461500830898826e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0461500830898826e-06\n",
            "[LightGBM] [Warning] num_iterations is set=150, num_iteration=150 will be ignored. Current value: num_iterations=150\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4048025290603312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4048025290603312\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
            "[LightGBM] [Warning] feature_fraction is set=0.25147880251501853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25147880251501853\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.30925898116807393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30925898116807393\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0461500830898826e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0461500830898826e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4048025290603312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4048025290603312\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.029228 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 228199\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3489\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
            "[LightGBM] [Warning] feature_fraction is set=0.25147880251501853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25147880251501853\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.30925898116807393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30925898116807393\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0461500830898826e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0461500830898826e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4048025290603312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4048025290603312\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.25147880251501853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25147880251501853\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.30925898116807393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30925898116807393\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0461500830898826e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0461500830898826e-06\n",
            "[LightGBM] [Warning] num_iterations is set=150, num_iteration=150 will be ignored. Current value: num_iterations=150\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4048025290603312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4048025290603312\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
            "[LightGBM] [Warning] feature_fraction is set=0.25147880251501853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25147880251501853\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.30925898116807393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30925898116807393\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0461500830898826e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0461500830898826e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4048025290603312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4048025290603312\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 16565, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.938669 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 227066\n",
            "[LightGBM] [Info] Number of data points in the train set: 39277, number of used features: 3486\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
            "[LightGBM] [Warning] feature_fraction is set=0.25147880251501853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25147880251501853\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.30925898116807393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30925898116807393\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0461500830898826e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0461500830898826e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4048025290603312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4048025290603312\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.25147880251501853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25147880251501853\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.30925898116807393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30925898116807393\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0461500830898826e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0461500830898826e-06\n",
            "[LightGBM] [Warning] num_iterations is set=150, num_iteration=150 will be ignored. Current value: num_iterations=150\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4048025290603312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4048025290603312\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
            "[LightGBM] [Warning] feature_fraction is set=0.25147880251501853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25147880251501853\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.30925898116807393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30925898116807393\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0461500830898826e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0461500830898826e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4048025290603312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4048025290603312\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.066030 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 228262\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3489\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
            "[LightGBM] [Warning] feature_fraction is set=0.25147880251501853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25147880251501853\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.30925898116807393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30925898116807393\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0461500830898826e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0461500830898826e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4048025290603312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4048025290603312\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.25147880251501853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25147880251501853\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.30925898116807393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30925898116807393\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0461500830898826e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0461500830898826e-06\n",
            "[LightGBM] [Warning] num_iterations is set=150, num_iteration=150 will be ignored. Current value: num_iterations=150\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4048025290603312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4048025290603312\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
            "[LightGBM] [Warning] feature_fraction is set=0.25147880251501853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25147880251501853\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.30925898116807393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30925898116807393\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0461500830898826e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0461500830898826e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4048025290603312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4048025290603312\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.983158 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 227418\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3487\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
            "[LightGBM] [Warning] feature_fraction is set=0.25147880251501853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25147880251501853\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.30925898116807393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30925898116807393\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0461500830898826e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0461500830898826e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4048025290603312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4048025290603312\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.25147880251501853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25147880251501853\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.30925898116807393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30925898116807393\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0461500830898826e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0461500830898826e-06\n",
            "[LightGBM] [Warning] num_iterations is set=150, num_iteration=150 will be ignored. Current value: num_iterations=150\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4048025290603312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4048025290603312\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
            "[LightGBM] [Warning] feature_fraction is set=0.25147880251501853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25147880251501853\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.30925898116807393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30925898116807393\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0461500830898826e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0461500830898826e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4048025290603312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4048025290603312\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Info] Number of positive: 16566, number of negative: 22712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.953737 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 227411\n",
            "[LightGBM] [Info] Number of data points in the train set: 39278, number of used features: 3488\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
            "[LightGBM] [Warning] feature_fraction is set=0.25147880251501853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25147880251501853\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.30925898116807393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30925898116807393\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0461500830898826e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0461500830898826e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4048025290603312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4048025290603312\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-31 01:16:21,441] Trial 19 finished with value: 0.7955071848065197 and parameters: {'num_leaves': 150, 'lambda_l1': 1.0461500830898826e-06, 'lambda_l2': 0.30925898116807393, 'feature_fraction': 0.25147880251501853, 'bagging_fraction': 0.4048025290603312, 'bagging_freq': 2, 'min_child_samples': 17, 'class_weight': 'balanced'}. Best is trial 18 with value: 0.8435378558379825.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create Optuna study and optimize the objective function\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "# Get the best hyperparameters and best F1 score\n",
        "best_params = study.best_params\n",
        "best_score = study.best_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pIZZ8TSBpx8",
        "outputId": "cfd6ba82-a539-44f6-a142-12e7c9b98612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num_leaves': 90, 'lambda_l1': 0.0004388081618673077, 'lambda_l2': 0.004050094092094895, 'feature_fraction': 0.48991173557781453, 'bagging_fraction': 0.4037551307865023, 'bagging_freq': 0, 'min_child_samples': 15, 'class_weight': 'balanced'}\n",
            "0.8435378558379825\n"
          ]
        }
      ],
      "source": [
        "print(best_params)\n",
        "print(best_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "wjwomooqBxIG",
        "outputId": "d8f1c6ec-1331-44e1-b304-5d37c7d84b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Info] Number of positive: 20707, number of negative: 28390\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.136488 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 266981\n",
            "[LightGBM] [Info] Number of data points in the train set: 49097, number of used features: 3496\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.48991173557781453, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48991173557781453\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004050094092094895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004050094092094895\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004388081618673077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004388081618673077\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4037551307865023, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4037551307865023\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "Accuracy score:0.7714\n",
            "Balanced accuracy score:0.7548\n",
            "F-1 score:0.7054\n",
            "ROC-AUC score:0.7548\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "best_model_lgb = lgb.LGBMClassifier(**best_params)\n",
        "best_model_lgb.fit(X_train_tfidf, y_train)\n",
        "predictions_best_lgb = best_model_lgb.predict(X_test_tfidf)\n",
        "predictions_best_proba_test = best_model_lgb.predict_proba(X_test_tfidf)[:, 1]\n",
        "eval_report(y_test, predictions_best_lgb)\n",
        "cm = confusion_matrix(y_test, predictions_best_lgb)\n",
        "confusion_matrix_visualization(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR6tl8HNCi3B",
        "outputId": "75e8c71b-682c-448c-c485-ccfdb0136ede"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightgbm.basic.Booster at 0x7dc1ba151870>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "model_lgb.booster_.save_model('/content/gdrive/My Drive/models_fake_news/model_lgb_best.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLiCUBQCIkA2",
        "outputId": "bfd7faed-9a94-4505-c11b-3f640c68ccc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.7358, treshold: 0.447\n"
          ]
        }
      ],
      "source": [
        "treshold_f1 = best_tresholds_f1(predictions_best_proba_train, y_train)\n",
        "print(f'F1 score: {treshold_f1[1]:.4f}, treshold: {treshold_f1[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEofXVu2Iy-x",
        "outputId": "3f37cc5e-fd04-407b-e8b8-aff5cfb60e2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7022773560451767"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "y_pred_463 = to_labels(predictions_best_proba_test, 0.426) #threshold = 0.36\n",
        "metrics.f1_score(y_test, y_pred_463)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM22SCCSlpuJMi3ohBljb5u",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}